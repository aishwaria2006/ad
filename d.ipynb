{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08713e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "                                            filepath     label\n",
      "0  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia\n",
      "1  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia\n",
      "2  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia\n",
      "3  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia\n",
      "4  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia\n",
      "\n",
      "File existence check:\n",
      "                                              filepath  file_exists\n",
      "0    D:\\projects\\Big Projects\\AD detection\\dementia...         True\n",
      "1    D:\\projects\\Big Projects\\AD detection\\dementia...         True\n",
      "2    D:\\projects\\Big Projects\\AD detection\\dementia...         True\n",
      "3    D:\\projects\\Big Projects\\AD detection\\dementia...         True\n",
      "4    D:\\projects\\Big Projects\\AD detection\\dementia...         True\n",
      "..                                                 ...          ...\n",
      "217  D:\\projects\\Big Projects\\AD detection\\nodement...         True\n",
      "218  D:\\projects\\Big Projects\\AD detection\\nodement...         True\n",
      "219  D:\\projects\\Big Projects\\AD detection\\nodement...         True\n",
      "220  D:\\projects\\Big Projects\\AD detection\\nodement...         True\n",
      "221  D:\\projects\\Big Projects\\AD detection\\nodement...         True\n",
      "\n",
      "[222 rows x 2 columns]\n",
      "\n",
      "Missing values:\n",
      "filepath       0\n",
      "label          0\n",
      "file_exists    0\n",
      "dtype: int64\n",
      "\n",
      "Unique labels: ['dementia' 'nodementia']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Check the content\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check if files exist\n",
    "print(\"\\nFile existence check:\")\n",
    "df['file_exists'] = df['filepath'].apply(lambda x: os.path.exists(x))\n",
    "print(df[['filepath', 'file_exists']])\n",
    "\n",
    "# Check for missing labels\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nUnique labels:\", df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "c:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded successfully: (441000,), Sample rate: 44100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACoi0lEQVR4nOzdd3iN5xsH8O/JHpKQREIIsfeOEWprzKpOpWhLjS5FF52qg1+nLlpKtbSqg1ZbpbT2DmJvIkEiggyJ7PP7g0ROcsb7nvPOc76f68p1cfKe895Jznif57mf+zYYjUYjiIiIiIiIiEhybmoHQEREREREROSsOOgmIiIiIiIikgkH3UREREREREQy4aCbiIiIiIiISCYcdBMRERERERHJhINuIiIiIiIiIplw0E1EREREREQkEw66iYiIiIiIiGTCQTcRERERERGRTDjoJiIi0ohffvkFBoMBy5Ytq/C9Vq1awWAwYM2aNRW+V69ePbRt21aJEC169dVXUatWLXh4eKBy5cqqxkJERKQlHHQTERFpRI8ePWAwGLB+/XqT269evYqDBw/C39+/wvfOnz+PM2fOoGfPnkqGauL333/HO++8g1GjRmHjxo1Yt26darEQERFpjYfaARAREdFNoaGhaN68OTZs2GBy+8aNG+Hh4YExY8ZUGHSX/F/NQfehQ4cAABMnTkRYWJgkj5mTkwM/Pz9JHouIiEhNXOkmIiLSkJ49e+L48eNITk4uvW3Dhg1o3749BgwYgD179iArK8vke+7u7ujatSvefPNNdOzYEcHBwQgMDETbtm2xYMECGI3G0uOHDBmC2rVro7i4uMK5O3bsaJKmbjQaMWfOHLRu3Rq+vr6oUqUK7r//fpw5c6b0mKioKLz66qsAgPDwcBgMBkyfPh0AUFxcjPfeew+NGzeGt7c3wsLCMGrUKJw/f97kvD169EDz5s2xadMmdO7cGX5+fhg9ejQSEhJgMBjw/vvv43//+x+ioqLg6+uLHj164MSJEygoKMDUqVMRERGBoKAg3HPPPUhNTXXsD0BERCQxDrqJiIg0pGTFuuxq9/r169G9e3d06dIFBoMBmzdvNvle27ZtERQUhISEBIwfPx4//fQTli9fjnvvvRfPPPMM3nrrrdLjR48ejcTERPz3338m5z127Bh27dqFxx57rPS28ePHY9KkSejTpw9+++03zJkzB4cPH0bnzp1x6dIlAMCKFSswZswYAMDq1auxfft2PP744wCAJ554Ai+99BLuvPNOrFy5Em+99RZWr16Nzp07Iy0tzeT8ycnJGDFiBIYPH45Vq1bhySefLP3eF198ga1bt+KLL77A119/jWPHjuGuu+7CmDFjcPnyZSxcuBDvvfce1q1bV3puIiIizTASERGRZly9etXo5uZmHDdunNFoNBrT0tKMBoPBuHr1aqPRaDR26NDB+PzzzxuNRqMxMTHRCMD44osvVnicoqIiY0FBgXHGjBnGkJAQY3FxsdFoNBoLCgqM4eHhxuHDh5sc/+KLLxq9vLyMaWlpRqPRaNy+fbsRgPHDDz80OS4pKcno6+trcs433njDCMB4+fLl0tuOHj1qBGB88sknTe6/c+dOIwDjyy+/XHpb9+7djQCM//77r8mxZ8+eNQIwtmrVylhUVFR6++zZs40AjIMHDzY5ftKkSUYAxoyMjAq/DyIiIrVwpZuIiEhDqlSpglatWpWudG/cuBHu7u7o0qULAKB79+6l+7jL7+f+77//0KdPHwQFBcHd3R2enp54/fXXceXKldK0aw8PD4wYMQLLly9HRkYGAKCoqAiLFy/G3XffjZCQEADAn3/+CYPBgBEjRqCwsLD0q1q1aibxWVIS26OPPmpye4cOHdCkSRP8+++/FX7uXr16mX2sAQMGwM3t9iVLkyZNAAADBw40Oa7k9sTERKuxERERKYmDbiIiIo3p2bMnTpw4gYsXL2L9+vVo164dKlWqBODmoHvfvn3IyMjA+vXr4eHhgTvuuAO7du1CbGwsAGD+/PnYunUrdu/ejVdeeQUAcOPGjdLHHz16NHJzc/Hjjz8CANasWYPk5GST1PJLly7BaDQiPDwcnp6eJl87duyokB5e3pUrVwAA1atXr/C9iIiI0u+XMHdcieDgYJP/e3l5Wb09NzfXamxERERKYvVyIiIijenZsyc++ugjbNiwARs2bMCAAQNKv3fHHXcAADZt2lRaYK1SpUr48ccf4enpiT///BM+Pj6lx//2228VHr9p06bo0KEDvvnmG4wfPx7ffPMNIiIiSgftwM1K6iX7x729vSs8hrnbyipZMU9OTkbNmjVNvnfx4kWEhoaa3GYwGKw+HhERkV5xpZuIiEhjunXrBnd3d/zyyy84fPgwevToUfq9oKAgtG7dGt9++y0SEhJKU8sNBgM8PDzg7u5eeuyNGzewePFis+d47LHHsHPnTmzZsgV//PEHHnnkEZP7Dho0CEajERcuXEB0dHSFrxYtWlj9GUpSxZcsWWJy++7du3H06FH07t1b1O+EiIhIr7jSTUREpDEl7b5+++03uLm5le7nLtG9e3fMnj0bwO393AMHDsRHH32E4cOHY9y4cbhy5Qo++OADiyvSw4YNw5QpUzBs2DDk5eVV2HvdpUsXjBs3Do899hji4uLQrVs3+Pv7Izk5GVu2bEGLFi3wxBNPWPwZGjVqhHHjxuGzzz6Dm5sb+vfvj4SEBLz22muIjIzE5MmT7f8FERER6QhXuomIiDSoZ8+eMBqNaNOmDQIDA02+1717dxiNRnh5eaFz584Abq4sL1y4EAcPHsRdd92FV155Bffffz+mTp1q9vFL+lqfP38eXbp0QcOGDSsc89VXX+Hzzz/Hpk2b8NBDD2HgwIF4/fXXkZ2djQ4dOtj8GebOnYtZs2Zh1apVGDRoEF555RXExsZi27ZtpennREREzs5gNBqNagdBRERERERE5Iy40k1EREREREQkEw66iYiIiIiIiGTCQTcRERERERGRTDjoJiIiIiIiIpIJB91EREREREREMuGgm4iIiIiIiEgmHmoHoHXFxcW4ePEiAgICYDAY1A6HiIiIiIiINMBoNCIrKwsRERFwc7O8ns1Btw0XL15EZGSk2mEQERERERGRBiUlJaFmzZoWv89Btw0BAQEAbv4iAwMDVY6GiIiIiIiItCAzMxORkZGlY0ZLOOi2oSSlPDAwkINuIiIiIiIiMmFrG7LuCqnNmTMHderUgY+PD9q1a4fNmzcLut/WrVvh4eGB1q1byxsgERERERER0S26GnQvW7YMkyZNwiuvvIJ9+/aha9eu6N+/PxITE63eLyMjA6NGjULv3r0VipSIiIiIiIgIMBiNRqPaQQjVsWNHtG3bFnPnzi29rUmTJhgyZAhmzpxp8X4PPfQQGjRoAHd3d/z222+Ij48XfM7MzEwEBQUhIyOD6eVEREREREQEQPhYUTcr3fn5+dizZw9iY2NNbo+NjcW2bdss3u+bb77B6dOn8cYbbwg6T15eHjIzM02+iIiIiIiIiOyhm0F3WloaioqKEB4ebnJ7eHg4UlJSzN7n5MmTmDp1Kr7//nt4eAirGTdz5kwEBQWVfrFdGBEREREREdlLN4PuEuUrwxmNRrPV4oqKijB8+HC8+eabaNiwoeDHnzZtGjIyMkq/kpKSHI6ZiIiIiIiIXJNuWoaFhobC3d29wqp2ampqhdVvAMjKykJcXBz27duHp59+GgBQXFwMo9EIDw8P/PPPP+jVq1eF+3l7e8Pb21ueH4KIiIiIiIhcim5Wur28vNCuXTusXbvW5Pa1a9eic+fOFY4PDAzEwYMHER8fX/o1YcIENGrUCPHx8ejYsaNSoRMREREREZGL0s1KNwBMmTIFI0eORHR0NGJiYjBv3jwkJiZiwoQJAG6mhl+4cAHfffcd3Nzc0Lx5c5P7h4WFwcfHp8LtRERERERERHLQ1aB76NChuHLlCmbMmIHk5GQ0b94cq1atQu3atQEAycnJNnt2ExERERERESlFV3261cA+3URERERERFSe0/XpJtKD/MJiRE39C+uPp6odChERERERaQAH3UQS+u/YzcH2Y9/sVjkSIiIiIiLSAg66iSR0o6AQAOBWsXU8ERERERG5IA66iSQUFeIPAHioQy2VIyEiIiIiIi3goJtIBp5c6iYiIiIiInDQTURERERERCQbDrqJiJyU0WjEhfQbaodBRERE5NI46CaSQW5BsdohEOG/Y6noMus/HDifrnYoRERERC6Lg24iGSyLSxJ87PK957GBfb1JBn8dTAYAXEzPVTkSIiIiItfloXYARK5uyk/7AQAJswaqHAk5m+V7L6gdAhEREZHL40o3ERERERERkUw46CYiIiIixfyx/yI6vrsORcVGtUMhIlIEB91EREREpJivN5/Bpcw8FBSx6ChRYVExzl3JVjsMkhkH3UQaMX3lYbVDICIiIiIFfbnxNLq/vwE5+YVqh0Iy4qCbSCMWbUtQOwQiIiLFpF3PUzsEItXtPHsVAFBQyO0WzoyDbiIiIiJS3B3/Ww+jkQMNcm0HzmcAAOLOXeXrwYlx0E1EREREqli2O0ntEIhUlXGjAAAw5ts47E1MVzcYkg0H3URERESkiqnLD6odApFmXMvOVzsEkgkH3UREREREREQy4aCbSEXcu0NERERE5Nw46CZSUUpmrtohEBERERGRjDjoJlJRUTFXukl+F9NvqB0CERERlZN0NUftEEghHHQTqSg9p0CWxzUajVi+93xpRUxybTP+PILsvEK1wyAiIidlNBqRnMEJXrHGfhendgikEA66iZzQ+Ws3MOWn/fhq42m1QyGNmL7ysNohEBGRk/rjQDJiZv6HM5evqx2KLmTkFGDX2as4lpJlcvvbfx1RKSKSGwfdRCoqlqmQWknaenIG94zTTVtPpakdAhGRrhiNRny18TRSs/hZasvhixkAgLTrbHklxJt/HMaDX22vcHvCFaabOyvdDbrnzJmDOnXqwMfHB+3atcPmzZstHrtlyxZ06dIFISEh8PX1RePGjfHxxx8rGC2RdR/+c0LtEDSvsKgYBUXFaodBREQ6YDQaJauXcjEjFzP/PoY565k1RtLam3jN4ve+33lOwUhIKboadC9btgyTJk3CK6+8gn379qFr167o378/EhMTzR7v7++Pp59+Gps2bcLRo0fx6quv4tVXX8W8efMUjpzIvI0nLsv6+LvOXpX18ZUwfvEeDDUzG0xERFTeqIW7MPBTywsyYpS09bySzdVbUs4rKw6pHQLJQFeD7o8++ghjxozB448/jiZNmmD27NmIjIzE3LlzzR7fpk0bDBs2DM2aNUNUVBRGjBiBvn37Wl0dJ3ImF5ygavW/x1KxNzFd7TCIiEjjEtKysflkWoV9skREatPNoDs/Px979uxBbGysye2xsbHYtm2boMfYt28ftm3bhu7du8sRIlEFBUXFeO6n/SwsQor6OS4JZ9Oy1Q6DiEhRZ9Lk+azdfpo1MYjIMR5qByBUWloaioqKEB4ebnJ7eHg4UlJSrN63Zs2auHz5MgoLCzF9+nQ8/vjjFo/Ny8tDXl5e6f8zMzMdC5xcWkpGLn7dex4GA/DBA63UDodcxAu/HEDbWpXVDoOISFEGGGR5XHPFwYxGIwwGec5HRM5HNyvdJcq/wQl509u8eTPi4uLw5ZdfYvbs2Vi6dKnFY2fOnImgoKDSr8jISEniJteWV8hCYKSsU6nMriAibSqfiZOaqa/q4Cv3X0TrGWvtLvKZcaMA6TnOuU/870PJWH3I+mIYkSvSzaA7NDQU7u7uFVa1U1NTK6x+l1enTh20aNECY8eOxeTJkzF9+nSLx06bNg0ZGRmlX0lJSVKETxI6dyUbH/5zvLTACRHZdpHt41zK8ZQsJF1l6xnSnu2nryAzt9Dktld+00fhqIJb3TSW7DiHjBsFyLdzQv3hr3fgnjnCtkbqzTdbEzBhyR61wyDSHN2kl3t5eaFdu3ZYu3Yt7rnnntLb165di7vvvlvw4xiNRpP08fK8vb3h7e3tUKwkr/dWH8dfB5MRHuiD4R1qwc1N++ldJy8pV9QlJ7+QRWSowkUtuZa+szcBAO5rWwMfPNCKabCkGXM2nKpw27kr+qhBMXLBTpMU9qW7EvF417qiH+fQBW5dJHI1uhl0A8CUKVMwcuRIREdHIyYmBvPmzUNiYiImTJgA4OYq9YULF/Ddd98BAL744gvUqlULjRs3BnCzb/cHH3yAZ555RrWfgRx37VZK1qu/HULD8AB0qBOsckS2KTkIfvSb3U7RKoyIHPfr3guYdV9LeLpz0E3aUKzTLLXtp69gxxnTz9a3/zpq16CbiFyPrgbdQ4cOxZUrVzBjxgwkJyejefPmWLVqFWrXrg0ASE5ONunZXVxcjGnTpuHs2bPw8PBAvXr1MGvWLIwfP16tH4EccORiJk6mmg5eeSFZEQfcrudUahbWH7uMsd148UcVXcrMRc0qfmqHQaQ7xWWyx4fN36FeIORy4pPS0apmELOUnIhu9nSXePLJJ5GQkIC8vDzs2bMH3bp1K/3eokWLsGHDhtL/P/PMMzh06BCys7ORkZGBvXv34oknnoCbm+5+bJdTVGzEoQsZuJyVhxX7zgMAxn4Xh2d/jDc5TstvRu+tPqbbGX3Sl2nLD+KdVUcBADfyi1SOhrTm220JaodApEvP/7Jf7RDIRQ35YisOnM9QOwySkK5Wusl1/LH/IiYti0fjagE4lpKFvs2q4UL6DbXDEmXOhtNoH6X91HfSv4vpt4ukLeIAi8ph9wTSkiwZ601sOSVtP21mjpGarjlphXtXxSVf0qSEW0VVSvZCl10wLt9qRMtOX77dtul6HgtbkfSMRqPJhNT5a6xYTUTadV3GQfeCLWdle2wiqVy5noeEK/ysFuJadj52JzjH5BcH3aQ7yRpufVR+VvLtv46W/vu3fReUDkf3LpXp3XqcFdnN+j3+otohkMaVzYQgUpuPp7vaIRCpSm+Zm2qatvwgHvhyu9phSIKDbtKkwiJ97oV+8ZeDFr8n517b9cdScdAJ9/5cLPPB9NfBZBUj0a6yExNE5vh6cZBDzm/zyctqh0BEEtvlJKvcAAfdpEEFRcX4fH3FPp56kHbdcg94c8q3GC8qtm+y4bFFu/HQPOeYCSyr0M7fhysJ9PUs/feExXEsvEIV/LGf2RDk/I5cZO9rNR1m73EiqzjoJs15p0xKdglXGXo5sl892wmrVjtLSpGc9iVeK/336sOXcPACB91U0Qs/swozEclH6iJ2RIBzdWThoJs0Z/WhlAq3HTifrnwgKthiR3qckW3JXNpPcefVDoF04Oc9fJ6Yk19YjHNX9FOck4jIldwo4KCbSFGZN1yj8vdlkenpALC3zErnITOrnPuT0h0JiYjIKRmNRvT+aAO6v7/B7q09JI2kqywsRUTOjYNu0hyx+6L1rPx1no+H+IJHaddvV0z/5N+TFb6/59y1CrcREbm6c1dySgd7zBhSzpHkint/K/l4qBCJ+vi8I3IdHHST5hTxQ8huuU6UhkNEJKf8omK1Q6BbLme5zmR7WTvPOlaZOa+wCD/tTkJ+ofaey5xQIDLFQTdpjpe7dE/Lq9n52H76imSP54h4lfalv/3XEbzz1xHsOec8bReIyssrLMJv+y6gkAMpIt0xGGwfo7Ss3ALZz+FoxfW1Ry7hxV8PYO2RSxJFJJ3kDLazJCqLg24SbfziOCzcclbRc77wi/nKuwtsxPHqbwcxbP4OOUIS7a8D8veZLjYzs1xsBOZvPosXfjkg+/mllJPvGvv4SRqrDiZj0rJ4bHbxCrpKDBSIpOZRvn+mBpxKvS77Obw8HLsMz8q9+Tl5PU97r3vWSSAyxUE3ibbm8CXM+POIoucs+WApz1b/WVfbz+zhZvklnZ6jvQ9la1bsu6B2CKQj17JvPr+vW3ivcAXbTqWhxfR/cPgi28YR6dGOM1ecJtW+bJFXss/xlCy1QyAJcdBNmsPZUfttPCG+5ZhWWZpoISLzSgpUJaTlmP3+sz/uUzIcIhLpoXk7LGb26c0n6yoWdiVxZv59TO0QSEIcdJPmuMuQZrZ4xzkO5onIpf0ebz0ziEhOOfmFWLzjnNphaIq5LWE7z9hff2XN4RQcS3Fsn7hUzqRlqx0C6cD1vELM23QaBS5Qj4WDbtKcABlah7z22yHsTnDOQmLmenMTERFpyfK9F/Dab4fUDkNTXv/9sCSP89KvB7E/KR3jF+/B6G92S/KYjgp00TZwJM7yvefx7qpj2KaRosdy4qCbNCe0krcsj5unsZYaGRLtsf7sv1OSPA4REZFcMm7oq66IWm4UFGH2uhOi77f55M3tZRdVqBpuLpMwU6dbxAqLitkFQ0ElWwm12PZOahx0k1O7lHm7IElqZq6mXtT/Ha/Y4oMJ8EREyriRX6R2CESlXvj59l7u2Xbsh75RoN7z+WSq8xT8GvNtHEYu2KV2GKW+3ZagdggkEQ66yWW88MsBvLFSO6ltZrZy4aO14me3pWQ0GrH6UArbdRHpmLl9olSRmoMUkp9WJ1WMFl6fP+85L/qxylbA+WL9aTsjclyxdtYzHLbxxGVsP6OdVOeZfx9VOwSSCAfd5FKW72UbKmvOXcnBhCV7sGCzsn3YiaTiLO127FFyLb9gC1+/QmivMzRJ6X+rtVn5efPJNMkeq7Kfp2SPRdrkTBMaro6DbnIpeYXFXMU149CFDOQWFCH/1j6m89duqBwRCZGek692CJoz488jaoegGj9vdwDA0WRtVC8mUtOus9osnpqcwc9XohLzN59ROwTFcNBNLmfrKe2kDZmjZLGZdUcuYeCnmzHosy348J/jip2XpPErMzeojJKCNEwuF8bPi9WVSXlXsjlZqlUX0zkhorR0iYoK6wEH3eS0LFWf1Hq/7qSrOYqd6/Hv4nD44s1Vsbhz1xQ7L0lDS4UBSX0ebjcTpgO8OZi0Ja+wCCMX7FQ7DHJBBhfb2HAx/Qa2nZIupV5Ooxdpo90aOScOuslpfbf9nNohEBEpzmDQ/kX98ZQsVSeNZv19DOlsYUUa8bYTb4t5aN4ODP9aHxNcx1Kcpwo7aQ8H3eS0XHlvpzlXdZ7SdjlL+d6jRHJ5Yskel61Km5VbgL6zN+GrjepVW15/LFW1c1NFBUVGbDpxWe0wVPO1ncUPk1XoyS1WooLZe0RaxkE3ifLpv+J7R9JtGS60d0Vqnu58uyrvUqb2L7jIvL8PpeCrja5TQKasgqKbW3w+VLlFImnLvE3KvB4uZeYKKjbo4abuZ86B8+k2j/HxdJc/EBfw274LGPjpZrXDICenu6vYOXPmoE6dOvDx8UG7du2webPlF8ny5ctx5513omrVqggMDERMTAzWrFmjYLTOR+0+0nrXasY/aofg1DaduOxShVC8PXT3Fq5ZF9Jv4Pd4FqZzFVeu6zvzR4922Oh9XOhgb6Stp4UVSR29aDf6f2J7gOXvre6A9pml+1Q9vxT00C0mt6AIk5bFl9a3IZKLrq7Yli1bhkmTJuGVV17Bvn370LVrV/Tv3x+JiYlmj9+0aRPuvPNOrFq1Cnv27EHPnj1x1113Yd8+/b+RacE1nacrU0XFRm0XmbNl1MJdmPRjvNphKOYrhVaGXMEjC3fh2R/jkVtQpHYopICsPO0PBpyNlP2pzSmfnn78kvn9uUIHVy/8csDhmBxx7or+07Jn/a3NXullWYpR71vySHt0Nej+6KOPMGbMGDz++ONo0qQJZs+ejcjISMydO9fs8bNnz8aLL76I9u3bo0GDBnj33XfRoEED/PHHHwpH7pxeXnFQ7RCcUtr1PFXOW1BUjAe+3A4AKNR4hXdrdiUo25vVaDRi4ZazuJylzt+Nblq5/6JD9z+Veh0AcDYtW4pwVKbt16/a2Sh/HUhW9fykDEc7lezRQUePgxcy1A7BKq32Si9r80nztQRYyVxZ6TnOP8mhm0F3fn4+9uzZg9jYWJPbY2NjsW3bNkGPUVxcjKysLAQHB1s8Ji8vD5mZmSZfZN5OHbyZ6tHPe86rct5DFzJL+/yGBnipEoMeXb6ehxl/HsHsddx6oab4pHSH7t+1QSgAwNcJ9kimaTx1+mGVKxk/9cNeVc9PJJUfdprP9FSaUeMTffZw9DOFbCu7/WCjCxRS1M2gOy0tDUVFRQgPDze5PTw8HCkpKYIe48MPP0R2djYefPBBi8fMnDkTQUFBpV+RkZEOxU3ak1eojfRRS5ncBTK20eGeVekl3koB5Eq3c0i4ouxK95srDyt6Pi3IKNOqSw97Pkka/ZtXUzsEksnAT7eoHQLp0ItltnC0qBGkYiTK0M2gu0T5/qNGo1FQT9KlS5di+vTpWLZsGcLCwiweN23aNGRkZJR+JSUlORwzaYtW9i2rkRb27K39zgVFxci2sqfx/FXXKUbmqMdEpqDdyC/Cm38cZk0EjRr7XZyi5/tmW4Ki59MaPW9lIXH8vDzUDoGINOTPMlt9BAzldE8374ChoaFwd3evsKqdmppaYfW7vGXLlmHMmDH4+eef0adPH6vHent7w9vb2+F4yX6pLrJiuEiCi21796xN+jEe+5Is71er5K2btwZJFRcbcfhiJprXCBQ0mQegNCVfqG2n0/DN1gTUrOKHMXfUsSdMALA6aUL2K2lnRUTSctauj+uPp6JnI8uLOaRNqVm5+GZrgsN7/0kaSS6w2KObt0AvLy+0a9cOa9euNbl97dq16Ny5s8X7LV26FI8++ih++OEHDBw4UO4wSQJyV4ysFewv6+M7qnO9EMHHGu1ctf/rYDIuplvu8bwsLgk38rWRhm9OVm4BFu84h2KJPyz/PZaKuz7fgu1lWtt8s/Us1h9LlewcJR/w+Q5uIxg6b7sU4VTw1cbT+Gm362X4lE15VkNBUTFOWqi2LNR/Ej5PlaKRxCNSQKCPp9ohyOKdv47K9tj2fsZrxYVr2h1ILdySgLkbTiPBCarEO4NKPs6/2KObQTcATJkyBV9//TUWLlyIo0ePYvLkyUhMTMSECRMA3EwNHzVqVOnxS5cuxahRo/Dhhx+iU6dOSElJQUpKCjIytF3tkeR131xhhffUsuWUsF6jcvv7kHYr/H723ym89tshTFoWj9WHhNV0EGL3rcrnqZm3sy3e/OOI6BRyJRy6IG2RR6PRiNyCIsz8+xhe/FXdVjlqOHBe3c+Frzaexp0fb8K20/a3VdomsE+xluzVQYVo0j61un4AkHWCem+i9l8f1urkaLk1X9JVDrZJWboadA8dOhSzZ8/GjBkz0Lp1a2zatAmrVq1C7dq1AQDJyckmPbu/+uorFBYW4qmnnkL16tVLv5599lm1fgQim9YdvaR2CACAGxrtV5xbUIR5t/pTr9x/EROW7EHU1L9KC5o5Yp4L972eve4kWkxfo3YYLmtfYjoAYPh8dSt7K+2Cyu3DSDnZMg5O/zks/nMzI0ea7BZHV6OtZVJZy0gjx5RUXHeFvcRaFKdwe1ct0NWgGwCefPJJJCQkIC8vD3v27EG3bt1Kv7do0SJs2LCh9P8bNmyA0Wis8LVo0SLlAycqo6QnMImXX2Q+LTvunPRv4Ecuuk7LwMU7zjnNfubP/zvp0P13nrmCB77cpmg/6aRrXHUhZyff+8vpyxU/U2tW8bV6n8/XO/Y+IRUtZlK5Ardbo20PN4661VC+rtHcDafVCURBuht0EzmDM2YuEEhb8guLMeDTzbI9/rcuXrVaTh/841jP9KHzdmB3wjXZ9mr+eeCiyf8/XnsCJy7xPYGcWxU/L9kee8GWsxVuaxVZ2ep95m8+yxRjIpWUrVzuKjjoJlKBVlO36TaxreXyRBZGS8nUdtrg15v1k2rvaHqnpSJq5yVe6S4uNiLpag7eX3Pc5PZP/tXGipvWFBcbMW35QRxPcazAHGlDWID2OsOU7RNMZM303w9j1UHXGyiSdDjoJlJBjoYrg5N9qgX6CDpu08nLMkdimdFoxKf/nhSUNv22jBV5lbBsd6LtgwBsPZWGVm/+I3M0Ny3dnYiu761XNG1dazaXe/4fSba8hSM7vxBLdyXivdXH5A6LNMDRjg7W5BYUocus/7C6XIHQk6nmJ3Sk7oxBQE6+douqCbFoewKe/H6v2mGQjnHQTaQCd4kqdxTpvJ2IGLvOKld048zl65i8LF6Wx16yQ9hgUA5Xs/Px0doT+HhtxfRrvbemKe+lXw8KOm7C4j0yR3Lb/qR0AK7ZC7zk+VX+dfXDTtuvh2ydX6zTTdP/OGL1+ykZ8mX/ZOUW4kL6DUxYYjposvRaPHslW/BjX5Qx7hL/Hr2En+L03cpRqy0NOb9CSuGgm0jHMm/IdzGak6et1fhjt1JMV8ZftHGk49YdTcXfErYik9qhC461t7qWk1/h8a5JVMlXb7Tc0kZvkjNu4LXfDlVYsZy97gRiP94EAEi7nm/uroo5cD5d1fOTZYG+0vbxLtvRwtI8d8aNApNV7YycAhQUFaPAQsFOtYz5Nk73qfCFNiYbM3IK8MX6UyhU+HdfJHLUfS1b2fcwS8VjSX846CZSgdj9wmrQ6mDEXMEcqQn961jrTyqngw4Ousvbp4NesGrIyFF3gKg3i7YmYPGOczhaLmV89rqTOGlHx4ZPZdjrPlVgBgQJl1dYhPXHUh3OlpF6cFH2fTLTQt0GwPTzuPP//sWLvxzAtWx9T0KuP67NVWVrluw8h/fXHMfeW+0TtWrkQmXbOvp6uit6PpIPB92kiPXHUvHWH4dtHucq+6heX2n7d6G2SwqkzEnpclaexe+NWxyHt/60ntpoD7HF06Qi595HZ5J23fJzQojcAv6exciVuEDk/M3ST7CZay1Fjvli/Wk8tmg3Dpx3bDLw/DX5ah0InejOzivCin0X4K7zNlJ/a7Dgl60CstdvTfQXFmv7fffQBWVbiQb4eCh6PpIPB91kt6xc4TPBzyzdhwVbE2xe8FxROG1HDUXFRl0Mmipp9I3e0sXTzL8tF1v65/AlRVbISVscHXR7e/Ij0lFlB+JzNpxSMZKb1Jgo++/YJbz22yHFz6uUkoyEdCuryUJU8ZM2vVysbafTFDmPHjLd5HDh2g2s2Hfe7PdOX77uEn2aXdUX60/hzo82am7bhtJ4RUF2iwz2E3xsyQxm31v7+lyZ3it4KsXShcm5K+yrWifU36H7rzuqv9RDe7z4ywHVtgDQTfvKpIq+t/q45QMV4uUu7rLn0IUMh3s5P/tjPBbvOAcAGPH1TqzXaEEpV/bjrkQMn69M2rCzFa2cs17YYHnOhlOYvGy/2cnQ1WVqqJy2YyuKXO74339qh+AU3l9zHCdTr6P/J5vVDkVVHHS7iNyCIqzYd17xAhDlFbpI+riWvS0wzVrt2fhgPy/Vzl1+T6oQFzNsp0aWn+W1t1ov082EOXA+w+RiTqyrKhf9kkNcgnJdAJzBoM+2YOQCxwZjWbm3J1q3nErDu6v03Y7PGU1dbrrXX+w2hHVHLgk+NkjEZ9ulTO1v8/pEYO2Fkss/W9sIX/v9sOjiZnKRc8uDUKlWts7pzSkNTaiogYNuF7Fy/0VMXrYfbd5aiwwXrVJMN30tMM1a7RVlc9VmHV1xcoS5wVvZQZmQYiflW7588I/6K3/OLsOBlNesvEJR22j04P4vt6sdgqrsKdaVIPF7YUl17Me/3e1wJwJy3JZTFdPKs0UWEp26XHhl8RB/4YNubw/Ll+lqfh7KzdzfhPRJzlaAesNBt4sou8KdledcF5Ekj8oq768z586PN8r22NtsfMhPWFKxn3OPDzaIOsfZy6a9Xx3dcyzW6sPmV33VKginBEdXKuLOsbK7LZOXxeP9NcdKM5kcmeiQ0zkRvZfllp5TgHVHU/HFevX3uSth9SF1C3uVzTYo79Fvdjv8+NkiWmx6iCzSZmlwPXej8+6BXr7X/N5va6TYCqIUbw/XqUh+39xtFW67ovC1j1Zw0O2ClG7HwHZEJBU5q0m/9rvzFjoq8cqK2z/j9TIrOdZWU/Ru3qYziJr6F37anWT7YLLLin0X8MX603C7lZ4idmvKQQerXguV7MCKS6LEq90ZN25OhFsbDOrNDzvPWfzettNXFIykIj1vbZtloUjojXzLA329bxv/Pf6i6Hocgz7bgq7vrcfZNGGTa38eUG8iyJk/c8u7kF5x4nve5jMqRKI+1/mrU6mJS/cper5Jy+IVPZ8zOHJR2ZYU5uj9Q1usHCsXMHLLLSjCT3FJKFSwsqfae/aV9uKvwtM/y9JDpwEAmtg2ZC4rwCig6/3Os8oMyBzJ3un2/nq77xt4qwZD2QJaJf+sHuQj6rEKioo1uy9yzWHL+5r9vfVVh8LagNbs8RK3yyuRW1CMv+xo/7XbCWo32PsRJSQ1XcxikFb2lzsTLXxeqYGDbieVW1BkcrGoZr/Z5HTu5xBL6L7DNRbShaWwYt8F2R6bTP15IBkv/nIAm05eVjsUE67e3kMtd34kfhvFEiurjEoxV4BQqYrQQriZKxQhwkUzKzZi9P6w4t/15z3nRW0z+XLDafT5aKPoPcdyEVqJ20dn6bQfrj0h6vgIkZMnQmXaWVPiqs7ary7dlajo+e6ZUzHl2ZLrGnmtkf5x0O2khn61HY8s3FX6//Qb6rwB5xYU2VW4Rm6/7BG/X0hJQtvavL9G3kJc76466jJ7DpVg6Zq/ZA+s0H2BbwmsQG+NkLYszl5lWcikgtiVSGs2HBc2qXLSjpXMTA3tow70Fbei/PZf+nieOVpc8oyFtFehLZeA29kEWpkQk2uFl8wT2us+U2fbFrRQJVxujyzchekrD9t1X2drM+eqOOh2UvvPZ2D7mdspe2oVbfh4nbjZYqU8//N+1c4tJF018aqwPUlypz3N23RG9oG9K6ksURs0KeoyDJu/w+YxjrTb0oO9AoqkeYrs62yNVlu/vLLiIF78Rbr3xEVbEyR7LC0pad8k9QXwtRx9rUrK5VJmnmyTCVdkbv93MSMXd3600e6VaaG00Oue7LPxxGUs2pZg1307vvuvtMGoKL+wGMcvZakdhio46HZyhUXFuOuzLVh/LFWV88clsIhaeUJWMycs2atAJOTKcguKMW+T9RU2RwpPaVF6ucGNkEkre6ro6s33OxPxU5x0P+fK/Rcleyyl7Dprew/s6kMpyMwtQOPXVovqy0zCfb1ZWEtLMY6nZJntPiG1k6nXzW4hcMT64/ZduzWtHihpHKQurU7Y2uOpH/Zin8IFnbWCg24nl1NQhIMXMnQzq5ScIT7FyFnTboS03dFi6r5U5Lj4IlPvrjrmUn2Cj5jZc2zLfJWeh2IH+4t3qL+nW8+Gf2177/nqwym4lp2PvEL7iluVkOITy1lrO8nxfnRZwQGL1Oc6dMH0PStAYEG6rg1DJY3DmiCR20nK0+NnkNjrTj3+jHJZ68ITlhx0OzlLewhz8iXY7yPDh77YiqGA+q1I5CKkkrWvp76K04hhz75WNen1GnjQZ1tw4pK+ftfl7RHaS9vOP9L0lYcrXGTlFhRhzznhFYLFps1O/fWgqOPVrL4vB0k+o+yQmVtQISNCao5sCyp5Hskdo7OYve4ErvJ3JSuxnTD+LZd5+cm/J6UMx2bZc7FbAMz1/ha7kOUM1eTJcRx0O6FPy7yBWWoPFv32OofPY+9lg7UVHIMd1WXN9WQsdtZlgHL8vJQZdAst3uLs5O4nrHQF1xJ6q3Rb3nyBPT89yu3PHvNtnKD7LdqWUGFQu3DrWdw3d3vpPl9bxHYDkDOLRYkiXCcdzK5Sq4fuw/N3YMgXW2U9h6e7G+78eJOo+1zLzsf0lYdR6dZKpz2flWoS0joOMN/T1xGz153E4u0Jkj6mHny18Yxi10G5Iovplf+cE1O9X4hvbOybbjn9H1GPZ66YrNCip0RlcdDthD4S0OpCilWREH/rRaG2nU4zuwI15Sdpi5iZm/FfuFW7qcmv/iZuBcua0Erekj2WNSzectP5a45VL7ZFrayNradt9zXVMnt3mDhSefnkrewAoRecL/5iX59wOWxWoDWdvQWDSuSIbNOTk1+IH3YmOlxc8uCFTCRcycHOM1ewbLflSbAV+y7gp7gku85hT+ux3+IvYNG2BEE9iLUo6aqwn1mOiWRHq85LTaltYcVGI3YnXEVeobYGiAfKTV7nSDyAPXNZWCFaoZwti4jUw0E3yea13w4pch4vj4pPYy23oNl0Up8XTeS80nO0027KHlpoWyRkO4hWZOcVIbegCBk5BUgpUyxPyhVBJffRAsAPOxPx8oqDggqiCTFq4S68ZCPFX8mJlJLshLKTCqlZuViik738AT7C9iLLQWtFqNIUiufghQw88OV2LN6u7eeIj6dyQxF7JuXs2fZI9nHWGk0lOOgm2dSs4qd2CESCKVGp21y634u/7MfCLdrNzNC6PeeuYrPKE1nbTqWh/it/I/HWitqF9Bv4TWQ6uZIS0rIxYcke3PnxRjy2aHfp7a/9fhiDP98iSdsjR7OfUzLFDUxO3Epnt3bR9sbvwnvk5glo7aiGsnG9+ccRvPrbIdnbVFmjhWtkvRWp8vNSZgIi61av7tMSr/yWV1Dk2JOgSMEnkdj95wCwy8x+bG8ziz1yO3xRX89ze+ix84UYHHQTaZSQjwa1ig2RfYL8TKu8pmTk4qe485LvY5SSuZoJWjL0K9v9xkukZkk/sdL9/Q146oebLf66vb8el7Py8PLyg5i0LF7yc0nlw7UnsOH4ZaRm5eFouYruB85nlE4eOMLNwVG32IvakoFMnpWMg+1nHN++kVtg+vgZEmSJXBeZSl/iyMWbfzu1Br7ZeYVo9sYaSR8zwY73mwWctDTruZ9vbuWz9/mllGJtzm+VcjNUbCmoVD2dsh5ZuEvxcypN6q0BWqO7QfecOXNQp04d+Pj4oF27dti8ebPFY5OTkzF8+HA0atQIbm5umDRpknKBuoA4oRWDVdCqZpDaITjszo9s9/ssfwFI2ubuZjoQOZai/VZ+o8ushGpRoYh0wad/uF1YUso0tmtlBl7nr+XglM4q7ztC6iJI9ioZWHz0j+2aJo7oO9u0AFqhHSOG8qvoa49cwp8HxK/wqHHhX1bJSmpZ9uxXLyvIz3qtGHPsWb10BSVbPP7Q8OphcbHRrlaOtuyUYIKtxIPRkXj8W+Gfg6sPJaPju+skL1iZdl3fBU9JZ4PuZcuWYdKkSXjllVewb98+dO3aFf3790diovliJ3l5eahatSpeeeUVtGrVSuFoXdvF9BvYeEL+Yj0W6ayyqznXdL7PluShdCqp1le6xSr5/a05nCLqfhk3+Ho0Z7JGVvRLBl72rJQ6QqoqxjvPWN+LfjG9YpaG0j+rED/HiesvT67taIrlAXeeA4sKQ+cJz4Cy5VpOPjLLTTD9fcjy58fCrQm4lJmn2S0qWhYaoExxYLXoatD90UcfYcyYMXj88cfRpEkTzJ49G5GRkZg7d67Z46OiovDJJ59g1KhRCArS/8qnUJXLpbCq4VOp+y6S6uKT0hU7V5yEPS1LUjDlZq6Xpxy+3sxUSkdsOH5zMvBIsrgsg4ckvIhzJlLtpz+V6ljWR6rIPeBSUaoSta+ZVe3sWwWefo5LwiKNdOxwdH/u0eRMJGeIWy1PNjMhQfqwLzHd4vdyCrSRFu/rWfG19/4adnSRQ/2qldQOQVa6GXTn5+djz549iI2NNbk9NjYW27ZtUykqSrXQo9bDXf8rzXqg5F7gp2/tW1XChxKmiA741PIWFHsUFRvx0Lwd2FEufU2pVHGlq0I7m4lL99mV9pcocFJl1t/HNL1HXwhH224B4lN+Xy9X5Cy3TJsjIS2fPG995niqUODImpz8wgqrZFIYVmYS6O2/jmL6H0ckP4daYmb+J2r7h4/KafZkv1etdLn5bZ/ttPjUrFzZC+l5ujv2nvLlxtN460/neX2S/bT16WRFWloaioqKEB4ebnJ7eHg4UlLEpQlak5eXh8zMTJMvsuyDfzjbJyc5Cj/Z6/w15QYSbiq8MzWtHijouNyCIuw4c4XZHDo29deDsv39dkrUskpNUqzenk3LFpWxUn4y6auNZ0r/LaSzQMmkyNVsbe17LPtzSCnFwoS3krJlLOQpxcQPyc9cRw6p/G/1MZvHPLFkLwZ9tsXs96SKLcfBlpSz/j4GPp0J0NGgu4Sh3F5do9FY4TZHzJw5E0FBQaVfkZGRkj221uQVOr4X7ZJKKX2uQmsXkErxcnBmWQliCniRtvy6l/tOrXF0ZQcAqvh5lVZPVkLZtkiLd5yr0Fv3v2OXBDyG+AJ4ti4/zki073ruhtOSPI6UxOy5VWr7jSs5I+L5ul+m7WGf/qfc5HN6Tn6F1/UeKwV9E65I89r760CyJI9TltYrymtBcbER56851/uG9q9sbwkNDYW7u3uFVe3U1NQKq9+OmDZtGjIyMkq/kpKSJHtsreFMsrSc7c2BtEnOlQXSJzXfe6JC/Cx+76pK1XZf++0Qmry+2uS2P/bbvnAW08dbavZUQdeTSj7K9KZ2JWKKrT76jTztplZbKSgmtdiPN2H8kj1mv2dP9X+5XbeyrWTovO0KRqJP321PwB3/W692GJLSzaDby8sL7dq1w9q1a01uX7t2LTp37izZeby9vREYGGjypSenUrOQrmDVa6lmEp1BQREHQy5FpT+3nzf3L5IpZ7swUYuaKdspAlLo9eCyhrZEqelsWjae/H4PTlzKQrZMq5pVRBTNdYZuKKlZedhkoStO2XaQJXzMFEBTUqeZ/1psXWZv14PDF+Xdv662mX8fLc3w3GOlyJ5e2TXoTk9Px9dff41p06bh6tWbe7b27t2LCxcuSBpceVOmTMHXX3+NhQsX4ujRo5g8eTISExMxYcIEADdXqUeNGmVyn/j4eMTHx+P69eu4fPky4uPjceSI8xY02HrKvt6Ea49cwqiF4mdCK/uqXyldK3w8dTOHRRLYZUeF9QsS7Is3V0mVSO/SbbRks2c7VK7IvZj29FffIlH1dn9vyyvBespKs1SN+qDMxa60ZuGWs1h1MAWxH2/CE98rV4SUtOX4JWkLrDp7QbYD5zOwbLfzZhiLzvc5cOAA+vTpg6CgICQkJGDs2LEIDg7GihUrcO7cOXz33XdyxAkAGDp0KK5cuYIZM2YgOTkZzZs3x6pVq1C7dm0AQHJycoWe3W3atCn99549e/DDDz+gdu3aSEhIkC1OPZrx52EkXdV3xV1XI2VbLVKGnwRVducovLfTW2PVoLVixT55J5nFCPTxkKVCtiN2nr2KACsDyfJsVeXPvFGIqgHiXj+Xs/IQGWw5/V0Kb6w8jEc6R8l6Dj2x1MXhzGVxWXFn0rLRMDxAipBUUbbmh6XVWbKtoKjYYo2JPedc7xoo84a23uflIEW9Ka0SfTU1ZcoUPProozh58iR8fHxKb+/fvz82bdokaXDmPPnkk0hISEBeXh727NmDbt26lX5v0aJF2LBhg8nxRqOxwpczD7jd7Kwpl1/o3PvJ9Krf7M2YvtL8PsOSfsOknJX7L+KHnYm2D3QieYXFOHA+Xe0wdOnLjdorfqUkR3s2O+qTMhXqtTRJIhettKp7/Ns4jPsuzqHHuKSB6uxaVlxsxP7z6mcP2PsSF5pyb62I2cSl8fadXGY5Zar66ylLheQnetC9e/dujB8/vsLtNWrUkLR1F9knUCPp3nyjkc6ibQkVKnYCQGUR+7lIGn8fSsE7q46qHYbivt12Tu0QNMNoNGKXwLZgs/6+2fLG3j6yUqUui/X15jP4fqfjf/McM+9b1vx9UNoqwb/sca0q9W/8brnnsZLWHb2Ef47YrhYvFa0VMRXTY9xeUrT1k0KGjW0hlgidkJu0LN7i97QyyVRejcq+pf+WusNPrhOvApdQea5WVqIH3T4+PmZ7Vx8/fhxVq1aVJCjSt7zCIizd5bx7MtSwdFfF1VUPe9MarJD+EckZGNWqGqdBO89exYNfCas8639rO4G9g78RC3badT9H/XkgGa+sOOTw4EFMoScA3PvqoB1nXC/dFgAqidjGoIQdZ65iX6LlVlaOyMorVGRQL5QSnw3rj6fKfg4pGcpcSWXmSlvALtUF2vSWZChlSfy70wLRg+67774bM2bMQEHBzV+GwWBAYmIipk6divvuu0/yAEl/hLRmkdLVbOd7YZY3488j+HLjadn3MGnno1we9vThJWD5XudPzRUq0Y5+w3kObN+xVQzsxV8OaG4/dwl7qwcfuVhxYt/ei/uSbWWu4HpeoeQX+WrRc7JcsdFocW+7FP6UoW+0vay1xbLm36PCMyHGf2e+TZhWlc1CMJcJUDb9XKxAF2q9d0AD2yekJnrQ/cEHH+Dy5csICwvDjRs30L17d9SvXx8BAQF455135IiRZFJQePtT7YqE/VSLFb7AcZV9k7P+Pob75m53yeIhUrG2P4z0R+s9y7NvpVcHOHChZOvt9Kc4+bKKTqVeR+zHG7H+mH0rTcl2tsF69seK7X86vPMvfrUjY2DepjOqpuKmZAhLgd159qrZbURiqdUbXWpXrut3Rc9aJXopnJC4IrYjalTxtX2QGZOX7UeSwAlMraTSC1W1knfpvzPNDLrvnbNNyXCsWrn/ouTbeqRS0jrMmYgedAcGBmLLli349ddfMWvWLDz99NNYtWoVNm7cCH9/fzliJJm0mvEPCouKsfPMldJKm9YuYlPNFDZhb2rl3Td3u1NXd5TTR2tPqB2CTRc1uk8tWeDgQUn/2jkYtNdLvxywq+ikXtu8TVoWjxOXruOxRbtxTaELoLiEqzh3xfzF+OId4veZly2mpgZvD2F/+8tZeZgrwQTyWAcLmGmFh4WK1eUZjUbNrYgp9VrRAjeD/ZvS7J0wLC42im4HqCS3Mk9dc69/ObMgxJq4dB+39SjI7um4Xr16oVevXlLGQiq4mp2PM2m3W3mM/nY3Fj3WweyxE5ZUTPEJC/Q2+X/nWf/Cw035FkM7z1yBv7cHmtcIUvzcanh/9XF8veWs2mFo3s4z9vWtt9eSHecwolNthx7j/TXH8fHQ1tIEJKGYmf/hq5Ht0LdZNbVDKaX0RMCyuCR4eoi/yNTqRIotZbdj/LArEU/1rC/7OV/97ZDFbCl7ikeqXadCzJjkhAQX4yft6DUuN3MT9lJxZOuGbNR+0umEvdu96r68SuJI7JNXWCR4Uo0IEDjo/vTTTwU/4MSJE+0OhpRnKHdFYK0N1d7EdJuPdzFdnTYfQ+ftAAAkzBqoyvmV9t128Ss+BoNzV4U0Z4mZ9l6nUq+jflglWc63dFei1UF3fJLtFRlz/YqzcgtwLCULD3wprICXXJbtTtLUoFsP8guLJenProbcgtsDGkf2IYphbRVow/HLyC0oqrBX/OvNZyzeJ1uClG1b1hxOQaPwAESFMtuvrKipf+Gn8TH4Y/9F0feVo1CoYmT+nGV3GGFOX76OiMr2pb8LUVhkhK2dBNtPq9OBQgit17poXC1AU1kBUhA06P74449N/n/58mXk5OSgcuXKAID09HT4+fkhLCyMg24dOiNRcSktvIA//fckJvZu4PR9x+3Z46SBP48m7E28JtugO8XGHtZ1AorHJFzJrnBbrw83mh2MK61akI/aIZhwJLVRKVOXH0CAxqor69n5azmoHxZgctvbf6nbxm/84j3w8XTDsbf6qxqHFgmt9F9eaCVv2wcBSM/RXuG4r7dYngSSgtB2W0oQui9bDS/9cgDbpvVWNQapJ/2uC+xvLsRhMwUrtcTemiBaJigP+OzZs6Vf77zzDlq3bo2jR4/i6tWruHr1Ko4ePYq2bdvirbfekjtektiec9cwf7NpmvLqQyl27ZfJkvDNwF4frT2BwqJiHE22/Way7ZR2ZyC1asU+7fe99bKxF/DFXw7Idu5AX8d7p5+/VjEVWQsDbi2S4vctlthFJmep/O4pcI+t3LLztLmXs2xWgKvQQqEjLbYz3HrK+ram3/c79p7w1cYzKNBIcTElMkkAIM2OwnoXnXDQVrOKn2SPNeSLraX/trVgoAZ7e8BrmehP0ddeew2fffYZGjVqVHpbo0aN8PHHH+PVV1+VNDiSn7l92hOW7MH8TfLO1F7LzseV63mSrbKXJXQV+L01xyU/t7ObvGy/2iHY5O1p3+AgVYKBrdKV+0l5P5jZsmDLMhkrjCtFK72Q7UluyLyhzITwOTNZKs7Mw12+TJP5VrYM6J2tQbkQzrAKuOpgiuBjtTDBowVHBCwoCVVYZga508x/MW259AsSl2Ss56BHoq9Ok5OTS3t0l1VUVIRLl4T33SNtO5oi/oUtpq1Mm7fWot3b69Drw42iz2PLOIE9HeOT0iU/N+mXFFsItZ/s7Jgr1/Pw1p9HWD1fJEdWQbMV2kutZ02qB1r9vj291e1hrn+yFG3ATqaK29dYqNAqqJzvd2uP8HrSmiw7+2PrlT0r3XI7m2Z+ku30ZX1Ovi3dlYQMibdraLUdmVpED7p79+6NsWPHIi4urnQPb1xcHMaPH48+ffpIHiAJczYtW9L0kGKBn9llU5ye/TFesvM7YgvTxnUvXcG0otSsXGTnFUpSuKeKv5cEEWnXmsOXsGDLWew9l652KC7D2etTiHU1O1/0oHLjCcsFQqX0vpnsqVwJJqjEFlBkFpf2WNqyp/eJWlvbuaRiaYArVo6E6fCWMtuC/fR7HaDUBKWrEv1qWbhwIWrUqIEOHTrAx8cH3t7e6NixI6pXr46vv/5ajhhJgH6zN+G+udvwvR2pj+ZsFThwrRZ4szLk/1Yfs/tcZy5fx7ZbFR7/U7jvLmlToYL933t/uBETluyRpMrpPgEV/p3B678f0kThRFfAjBxTj36zGyMW7BR1n09V7NVdRcQFuKULXrGrmqu4uqQ5P1vYYqL7d1GFZg1C/IUV1rNFyiytTyy8r+h5m9n2M9IuWqVdl2ZbgLsOiqYKIXrQXbVqVaxatQrHjh3Dzz//jJ9++glHjx7FqlWrEBYWJkeMJEBeYTEupN/ArrNXJXk8oUXRft17HkajEXM3nLb7XL0+3Ijh829eRH250f7HkYszFnNwhDO1KykqNiIrtxCbT6ahko829qzqwcnU60i6qs/e03rjbiUDQ4rUZT3acUaazzk5OPI3CZDoPcgVi7pp3Wu/H5b08XaccXxfuLOr4idvoc1/j5pfJAoPlLfLxxEZq44bJJ5Fsfb5ZU1qlmnmrps26ng6zO4fo2HDhhg8eDDuvvtuNGzYUMqYSAO8PJzkGe6gbafS0OrNf3DwvH39lZ1RpsYnIbJyC/HG74fwe/wFi2moJX+rsu03rPWoV9q/ZVqLzVylbjskS/Q8m68n/l6WB2JCWtBJZV9SOoxGI7Jyb7/+jUYjEq4wHbGs8tW07ekE4qjqGmvtR7dJtQ3Q3FYGW6TeZnEq9bpi21/s+bzxV6n44+Id52R9/Lf+PCLbY1evrI33Dmed1Bf9jBw9erTV7y9cuNDuYEg7xLyRFjrRymdZX6w/VfrBdibtOlrUDLJ6/Mr4i0qERQJ8u/0cvt1+DqNiapv9/oQle/DrE51luSBOu54nuMesJWO+jUPCrIGIT0rHVzJ3EiBtu5pjOT0vT8H93n8dSEa9UH98+t8pnHl3ANzcDJJW0hXr74PJ6N+iumrnt6T856GSfyNn0/+TTVg2PgaBPsq3BpRDTn4hOs38V7XzH0hKR/eGVc1+72L6DYQFeMNDxB7t8YvjpArNJnsm+5tFWC+wKAclJiF87OzQIuixPdwlfbzyK9ZCKVUrQGmif6pr166ZfKWmpuK///7D8uXLkZ6eLkOIpHUNXvlbsscaGh0p2WMJkWOlMnDZmeRnf4zHwi1nLR4LiO/fS/Kz1GZkz7lrAOxbLbAl+u11kqTgD/hks0kfTXJNE5fus/g9pXe5/bDr5r7Uku1HD4os8CWlJ77fq9q5renjYEcOo9HIegm3HE3OwslL1tuKKln/w1EX09Vdvftw7QmztxcUFaPzrP/w6X+nRD2eFFW6hbadm7r8oKjHNQDwNDNwW31IeJsye2Tmyp8JqKdMVHN/AyGcJZ28PNE/1ooVK0y+/vzzT5w5cwYPPfQQOnXqJEeM5CJW7DtfITVPbmL2RdnqGxqfdM3RcHThrb/kS20Cbra7OXjBdjq/EOZa+JT1y57zkpynvN/2XXD4MdRcRSTtKywqxnM/71f0nKVte4zAP4dTkO2ie8qtSc3KQ7qV7ARrDl3IwEPzdmD0ot0SR6Vf1uon5RUW4ekftDn5Ys57q9WvKr/nXMV6CEm3Cvj9sFN4WnSSRFWu5Zo0MQLYftr0+i4ztwCvS7y3nqw7Z+f2I2fdrinJXIKbmxsmT56Mjz/+WIqHIw1ypFCaUJOX7cdPcfIMgiyxtKBQYGYvcLKNvVh7JapcrfUajcv3Oj6gtCbVCd5sj6VkcrWKZKVm2vLhixkYt3iPaucv78QlcX2s5VZg50AiO78IO89exXoH60skSNReSQvcrIy6H/82DvsF1FvRin800Hv8vrm3s1OMRiNWHUxGr1vZGb5ewlOL9dBa6kq5TDcjd3rYNPvfE3ZPGppTNcC+rXZqdpyQk2QL+KdPn0Zhobi2FqRt68p8QDjSEkzLTl82n7pmKa33B4laslmjh6GaVLPc5pib8JCDnIPi+ZvP4vNyqXrOVPVdK37abb4Nj15ZGl4okbIohpS9bh1xNi0bCWnZmn5tHbBzUGjvXkgA8PaUdl+mmqzt7dx8Utr2Rq7mbFo2niyzTeN6biGMRqPFbVkl1h9LxcNfi2vb56we+2aX2iHYxVI9m0MXMjFHwkW2SnYWs5NqEUtrRA+6p0yZYvI1efJkPPTQQxg6dCiGDh0qR4ykkse/i0Oxhi9mpPDuqmMVBl95hUU4bKElw8srDjp0MeQs/pKxD6yYnrSOZAVI1V7Pkm+3J5j8v97Lq2Q9n9LKryKoIema9ldbxLD0bnuPmUlA535nFmbkgp2yv47tMeWneLy3+pjF7glCdHjnZsEte/q0p13Pc+jcQl1SICtpzLe7TbpMkDSKi42lK9wlruUUoM60VWj71lpcyrR8nfOMlToTrsbRrBQlFRQV44/9F7F4xznsPWd5O6RUFfapItFTEPv2mb7Y3NzcULVqVXz44Yc2K5uT/sz+9ySm3KmNlnAGyHOhaTSa7hvrN3uz1ePnbzqDaf2bwK1M/8F/DstbnENrKvvKV032vIiBlCPPh6Hzdjhwb9vSrqs/KJXTxKX7sHVqL1VjeKxzFKb/IW+NAa26puKkx/ci9n7KydaWH7VsPpmGzSfT7F7lLpGZW4A/99vXFePnPecxrEMth85vi7Uif1JJzsjFwE83Y+MLPWU/l6v4ZN1J/LLXepbQtZx8i/2mg3w9dTMRUlhULKoiu7NKupqDru+tF3RsSCUvmaNxXaIH3evXC/ujkXM4fy0H2Rp5c5VrZSe3sAh+ZXrhnrWxH27+5rM4kpyJ7x+/XThQS/sblXD+mnxVWL0lbllB8riQfgNHkzPRpLrybVlKlJ34cma1gv0q3GatwJQY9kxmamV1R0hauVyTtUJsOeVY+vMbvx/GCjuLMl4XkTEE3Fz51OrryVwxJi1vKdC6j9eZr2JeVnqOtra02OvXvecxtP3Nyae8Inm2xZQM7D9ZdxKLdyTIco6y1hy+hNTMXIRZmBQxR+iAGwC+2ZqAEZ1qo17VSvaER1aInv7p1auX2dZgmZmZ6NVL3VUPkl71IB80e2ON2mHI6p2/jpb+W+h+4q2nhFc9d0b1w/hmTLC4DcNZaGUIsv74Zaw+JM+WDr0PXWx1OtDzz/e3gL+5pefoO6uOWvjObZez8jDz76OYv+kM6r68CtOWH8Dv8fIWypTKkh3ayLZwVueuWF58yNJYjQlrjqXcLrKYkyfPoHvw51ux+eRlfLzuhGIZbh3eFd7v3Z76NTvOXIHRaERyxg2H6t8Us6CsCdGD7g0bNiA/v+KTKjc3F5s3W0/LJfn4ylQ45ZqTzHZa832Z4mgXZFzBdSblW3EIcTYt2+lrBMhBKwM/c7adVq+QUVGxEfuT5K1crKVn64QltwsepWbl4o7/MesMABY78eArt8D2JLA9z9Gkqzlo8cYatH9nHb7aeKZ0gL50VxKe/TFeUD9pJfaMWzqf0WjEGyvZ+klOL/16EPd/uc3s37lmlYqZN1pV9pojX6bn7JHkTIxcoN2CavZUmg/w8cSkZfGImfmfQ73Nt9lxrejMBA+6Dxw4gAMHDgAAjhw5Uvr/AwcOYN++fViwYAFq1KghW6CkDiWqdTtC6gHJ8yL63s782/ZKgrNaFpeE/47drG4/f9MZbDieava4nPxC/HUgGUcuZqLnBxuwZOc5xCVcRUFRMZ76fq/mWv3IYfWhZJtbFqzR0sCvPDHt45IzbuD8tRzkFhShuNjo8N9+0bYE/LpX2RaD9pLyfaqo2Iipvx6U8BHJWeWXayt3If0GdidcRa8PNyDLyraxzrP+szmhdt+X261+X2q/x9/e234k2bkzbLQiLuEaNp4w3UrS+s1/dPX731mm0GLsx5tUjEReGTcK8Prvh8zutX9XQNZLeWuPXCp9zT3x/V676hYVFxtxKtV8hyBXJXhPd+vWrWEwGGAwGMymkfv6+uKzzz6TNDhz5syZg/fffx/Jyclo1qwZZs+eja5du1o8fuPGjZgyZQoOHz6MiIgIvPjii5gwYYLscZIypBqQFBQV49UVhxBnpaJjeV9tvFlQzVWNXhSHbx5tX7pKkjBrYOn34hKu4tXfDpmkdgHA67/fXJ14skc9/HUwGX8dTDa5H6Du6qnU1hxOMVmhdEY/xSXhwehIi99vM+MftKlVBUeSMytURf3zmTvQvEYQ5m06jbTr+Xh5QBPBe0vf+lM/BdSkep+KmvoXujesWuFCmMichq/+jd+f6oJWkZVx6EIGRi3cZbMdVInh82+2hPpyRFv0a17d5HvbT1/BfjuqqjviuZ/3o3+Lali8/Rxm/u2cLUy1aMy3cTg7cwAMBgOKi41Iv6Gv7MdjKVnYfPIyujaoqnYokjuWkolNJy5jbNe6WBl/Ad9tP4d2tasgtmk1k57r9lQj/6NcAcdxi/fggwda4YM1x/Hf891xPbcQexOvVXhvKBGXcBX3KzwxpwcGo8Bk/XPnzsFoNKJu3brYtWsXqla9/QT28vJCWFgY3N3lLYC0bNkyjBw5EnPmzEGXLl3w1Vdf4euvv8aRI0dQq1bFKp1nz55F8+bNMXbsWIwfPx5bt27Fk08+iaVLl+K+++4TdM7MzEwEBQUhIyMDgYHqFQyypclrq3HDQt89uahZoEYr3hzcjGlut2x+sSceWbgLA1tWx2flelRbc3RGP/h4uuHfo6k4k3Yd767iBZXeRFT2wb9TeiD9Rj5+3JWErNxC1Ar2xYAW1W3uPQvx9zLbfuzLEW0xYcleTL+rKQa2jEDVAG88PH8H2tWugnHd66G5k9eaUBLfy53XfW1rIjUrV5Ke1n88fQfOpF3Hsz/GOx4Y6cbzsQ3xdK8GyMkvRNPX9fm+u+vl3qL2QTuDtrUq4+GOtfGciAxOIb4a2Q7jyxUP3j6tFwqLjPD2dIMBBrR/Z52k5/R0N+DkOwMkfUwpCR0rCh50a0HHjh3Rtm1bzJ07t/S2Jk2aYMiQIZg5c2aF41966SWsXLkSR4/eTq2YMGEC9u/fj+3bhc3AcNCtT7yI1I8RnWphyQ5tb2Mg27w83Cqks0rpowdbYcpP0l48EBERkbY5y6BbUHr5ypUr0b9/f3h6emLlypVWjx08eLC4SAXKz8/Hnj17MHXqVJPbY2NjsW3bNrP32b59O2JjY01u69u3LxYsWICCggJ4esrXa5jUxQG3fnDA7RzkHHAD4ICbiIiIdEvQoHvIkCFISUlBWFgYhgwZYvE4g8GAIpn64KWlpaGoqAjh4eEmt4eHhyMlxfwG/5SUFLPHFxYWIi0tDdWrV9yLkJeXh7y8vNL/Z2bqp2AEERERERERaYug6uXFxcUICwsr/belL7kG3GUZDKYFdoxGY4XbbB1v7vYSM2fORFBQUOlXZKTlAkFERERERERE1oju062W0NBQuLu7V1jVTk1NrbCaXaJatWpmj/fw8EBISIjZ+0ybNg0ZGRmlX0lJSdL8AERERERERORyBKWXf/rpp4IfcOLEiXYHY42XlxfatWuHtWvX4p577im9fe3atbj77rvN3icmJgZ//PGHyW3//PMPoqOjLe7n9vb2hre3t3SBkypYSE0/2tSqjH2J6WqHQRr3xl1N8eYf+mkTRkRERFRC0KD7448/FvRgBoNBtkE3AEyZMgUjR45EdHQ0YmJiMG/ePCQmJpb23Z42bRouXLiA7777DsDNSuWff/45pkyZgrFjx2L79u1YsGABli5dKluMrkTLA1ul4prYqz4+FdEey5n991x3DPpsCx6MjsSibQmC7/f94x3h5e6GZXFJOHs5G19vOStfkCQLDzcDDkyPxZXr+Vi0LQFp1/MQ7O+Foe0j0W/2Zrse8917WuDlFQcxqU8DPBAdiYggH3y7LQE9G4dhQvd66Ohi7V+I7DGkdQT2JaXj3JUchx/r+8c74kxaNl777ZAEkZFejO9eF9P6N8GV63lo97a0raCU8u9z3dH7w41qh6Go0EpemNi7AV7/Xdq2tp8Na4Nnlu4zuW3TCz2RX1QEbw935BUWo89HrvW7FkrQoPvsWW1cBA8dOhRXrlzBjBkzkJycjObNm2PVqlWoXbs2ACA5ORmJibcrIdepUwerVq3C5MmT8cUXXyAiIgKffvqp4B7dZJ1WB9z2TAYce6sfnv5hH9YdvSTqflNiG2FKbCNETf1L5BmdwxfD2+KpH/YCAOpWrYQjM/oBADrVDcET3++BpYaED3eshe933nyt+nl53Lrt5us4O78IS3c5R0XzDx9oJXmPTK15eUBjjOtWDwDgF+yB1wY1rXBM3VB/JGfkVmhruGxcJ3SsG4IP1hzHtZx8vHNPC+QV3vzgBoDhHWuZHL/hhZ4y/RT60a52Few5d03tMEgnhnesjdkPtcGus1fx4FfCWqWW9e49LUxeh13qhyLYz6v0fV9JB6fHYs6G05i74bTi53ZlL/ZtDACo4uelciT2mfNwW9SrWkntMCT3w9iO2HD8Ml7q1xjfbkvAjD+P4OOhrdC9YRiC/W//rX7dcx77z2c4fL7XBzXFe2uOoXujqtjyUk9sO30FD0abr3u1eEwHjFywy+FzOhuH+nTbKkrmDNinW9ukWm1PmDUQANBv9iYcS8kSdJ8RnWrh7SEtAMAlB92fD2+DQS0jMHvdCTSuFoh+zatVOCYjpwDL951Hm1pVMOSLrZjavzEaVQtA53ohGPttHF7s1xjNawSZ3Gf9sVQ8tmi3Uj+GrBJmDcTPcUloWbMy+s7epHY4sih57dg8Li0bhcXFCK3kDT8vD+w5dw0x9czX1hBi7obT+N/qY3bfX0lSvk/lFRbhkYW7sOPMVQkekZzZ8bf7lU5gAcDZtGwkXc3BqIW2L4bnPtwW/VtU7PBSIvrttUi7ni9JnEK8PaQ5RnS6OTF76EIGBn22RbFzu7JPHmqNu1vXKP2/3q516oT6Y/3zPQDoL3Zbyn72Xs3Ox9t/HsEbdzVDkJ/p9tnRi3bjv2Opoh57QItqWHXwdk2sj4e2wj1taop6jKJiI+q9vErUfSxxlj7ddhVSW7BgAZo3bw4fHx/4+PigefPm+Prrr+0OlrTr/nbiXmRKk3q1/fPhbQQf+9bdzSU+u370aRKGQS0jAACT+jQ0O+AGgCA/TzzWpQ5aR1bGn8/cgTF31EHPRmHw9nDHd2M6VhhwO6MHoiPRqFqA3ffX8pTmwJaWL8rLiwr1R/2wAFT284KXh5tDA24AeLxrHcQ2NV9EU2ukfJ/y9nDHhw+2lvARyVmVHXADNwcg3RpWxbop3azeb9MLPa0OuAFgy0u9HI5PjLIras0itLsA4kwahlXCgHLPg9PvDtDV779bg9DSf//5zB0qRiKvYH8vfDS0dYUBNwC8PKCJ6Mfr26waut763X3yUGvRA24AcHczoG5Vf9H3c2aiB92vvfYann32Wdx11134+eef8fPPP+Ouu+7C5MmT8eqrr8oRIwkg1yp3eKDzF5W7p83tWdxawcLfIJw5w8OWu1pFiL5P8xpB8HTXTcMEzdDqNg4A6NkoTLVze7q74Y4yF1Ry0NIr/L37W5b+u0ZlX2x5ian2ADDYjvciZ2LPc7R+WAASZg3Ejmm9MaxDJCb2qg8A6NssHLPubYFaIX42H8PH093mMVLy8rj92WEwGDC1f2NFz+9qXh3YBP9M6V7hM9vdzYDz126oFJV4bm63XyGVvAXtqBWtRmVfzB8VLctjS6GeHQPf7LwifDe6A9ZO7ubQe2xMXccm152N6Gfg3LlzMX/+fAwbNqz0tsGDB6Nly5Z45pln8Pbbb0saIKkrJSMPh97si+ZvrFE7FNm8PeT2inXZD3ZrWtZ0/hVaa05cEpaCT86tUbj9K/h6oJUJj56NqlrcO+coLRfEFOKO+qFYuf+ixe/r+ecrn+JpjqWf7eUBtgel1YJ8MPPem5M5T/WqX2FlXMvG3FEHs/7Wx/YSPWoWYfkap5K3BzJuFCgYjf3qltnL7ecl/vkt5P3jv+e7w9vDHaO71MHCrcrUwNr8ovBJV3sWiNrWrgyDwYAGDn7Gc6HFlOjfRlFREaKjK87otGvXDoWFhZIEReLJtSJTNcBbttlBrfAtN2Nf2Ux6TlnDOkTilwmdTW77eGgryePSssgqtldC7JVX6Hq1CfQotJIXWqg8+WR/RRJ9Sc7IrXCbVD+7PQ/ToU6wNCd3kJBrSTWfIm1rVXbo/m8PaYFhHeybbCkpUCmUlgfcZYtCleDFvP3Gdq1jcwBaxd/6dZBeDC0zWWnPc1zI+0fJ475+V1PEvdpH9DnE6tssHJHB4q7B/n62q+BjH+sShcbV9LOFQE9Ev2uNGDECc+fOrXD7vHnz8PDDD0sSFIkn14XF87ENZXpk7do+tbfV7z/Tq0GFFXF79rvoWbqMs9wRlX0FH+vIZNMPj3d04N62hVbSZ6VXob4Y3lbtEPD9znNqh6CITDOvN1uTg3Ia17WuaucuKyxAm9ufGoRVwrAOkfhhbCeHHifY3wv3tbXvs+WBaPk/kz58QP7JZg83A9ZN6S77eVzJKwOb4uD0vlaPCfK1/P5yLUe5AnqOEpq96OyaVA/EoTf74s3BzfBkj3pY8IjldPjLWXkKRuZa7FrCXLBgAf755x906nTzA2XHjh1ISkrCqFGjMGXKlNLjPvroI2miJFV8OqwNPJx8NvmpnvVM9vwAgK+XO2pW8TW7b+nVgU1EDQqdlZwFrKx92JfnyGRTJ5n3Gt3fznSF6vjb/dDo1dWynlNJ4YE+aoeAAB/nWI2x5a+JFVcp3Fy4pkSJ70Z3hBY/on4Y2wlVHZwQKEkfbVe7iuj7hvh7KbJyXbOK/J+FK5++w+xKNznG3c2A1ZO6ot/szaW3VfHzxJ5X78SF9BuoHmT5b/vBA63w5PfKt4zTIj1tNazk7YFHOkcBAHKt1IHSwme7sxL9cXXo0CG0bdsWVatWxenTp3H69GlUrVoVbdu2xaFDh7Bv3z7s27cP8fHxMoRLSipbPOHpnvVVjEQ+bWuZv6BZO9n8zPrjGlnhUVtdGXteKjXRU36yRUqPxNTGi30bmdym5fRNvRoVU1vtEBRRRWODDm9PbYx0G1ULQP0wbdcVsPeivCR91J79mHmFxXadU4sKiiz/LNF2TEjQbY3CA/C/+1qU/t/f2wNubgabqcsDWlTH9zJniunFyqf1WRHdUiHEWsF+eLJHPcnOk51n37ZjZ60XI3qle/369XLEQRr3fN9G+Hz9KVnP8faQ5th77hqW77sg63mE8DWz36majdm/ZhGBOHwxU66QNKNvM3nbNGk1ZVSMphGBsg7q6SZX7iDgrWLaZIsaQfh4aCtMXrZftRjKalI9EEeTtfPe6+HAa79+WCVUcXDrQJ1Q52nTU2SleMGi0R3Q9+NNuJCuj2raXRuEYvPJNFVjKLutymAwYGj7WmgVWRn9Zm/GjXzh9VT0kPFXft+6QRtzhZr2+qCmCKkk3TXYJTtT1acNaIxHv9ktWRxawacgacaITrUVL44ipiDQiE61rH6/Yx3XaI0w696Wtg9ygKe7G1pI1L97oI1es3fKlCZ/r537MMsSk2ZPrsfD3Q0fKLCntqySlGmDweBydSzEsDczoWOdYKyZ1A1LHdwL7kysFQys5O2hqxXXVwc2VTsEdK5fsc1ivVuZa/eLqAMg1cSOIxNU1hgA9Gli+vke6OOJF8ploJG86ghoP2hOqIQDfy0RPcLJzc3F+++/jwEDBiA6Ohpt27Y1+SLXc/hN6wU5xFi+77xkjyWEtT2hY7vWKf33Bw+0wlNOmmLvzEIsFDNrFnGzMuebg5tJfs5tU3tJMnm0/41Y/DQ+RoKISM/K9udW25DWN7ccBdzqaLH8yc7WDpeVVjtG7H891qH7u7sZnL6WilA1q/ja7DGsla0OQtRQYA+8Nc/dab4wrqe7G9ZN6YYpFr5viRR7+guLhVVmeatMa1chjDC/b1nuAoMBPvJ3+yks0k/bDmfa6iIF0c+O0aNHY+3atbj//vvRoUMHl07vc2ZiUhft6X1oSYGG3kxeGdgUXeqH4tFvdqNeVX+bz/WBLasr1qORrBvUsjq61A/F5pOXzX7/61uVO/1laIcnRdpdSWXwDnWC8XDHWvh+Z6LDj0n6FGGloJGnu3Kfv70ah+Glfo0xtlvd0q0TrWtWVuz85Wl1pd3Tw/Rv4sUBtN22vNRL7RAkVcnbA1te6ok7/qfONs3G1S23gbKnNsK8kdEY8Olm2wdKIMSO7JHjl7JkiMQ6JWq3yNkjXepBsr1F2Zx1sC76ivOvv/7CqlWr0KVLFzniIY1w1ie8WN0bVsW2qb0EDaQiKrtGxUclZnIdEeDjgc9vDVq3nb5i9piSyqz+ZSaMujWsik0nzA/SlTaw5e20+LeHNOeg24XdsFJltnz6pJw61wuBh7sbwgJuv8+5uRkQFeKHhCs5isWhdQZU7IahtJTMin3dSRtqVrEv3ba8ib0b4NN/T4q6T58mYZKcu0TTiEB4ebghX4HrRXu6NeSI2KMupUc7R2HRtgTZHv/VQfJtU0jO0EZ9hBo6qBlgD9FTsDVq1EBAgHNWldO7AB8P1LZz/0R5PgJTth5oVxMGg8Hmfmdr/nzmjtKegY48jhwMBoMuCoYoyZlSHz3c3eDhbkD7qCrIszK4UZMWs4mqBnhL9l5D1uXkW67+Kkemhh60iqysdggWOTLIzsy1r9JveWoW2SPzXh3YRNLH696wquj7aPGzRE5y95vuVNd8TSC5C/u1lvH9r9haEQU7FBbbNyFTLch0EUvgLgTNE/3O/OGHH+Kll17CuXPn5IiH7PT3s13x5zN3iN6TY4nQN/TkjJsz6m8PaWHjSMua1whC71srNoNb1bD7cch5KFn5e/1zPTB/VLTZvuxitalV2fGAdOCToa1d7gJOLe2jhBd7dAVzH26LZePEFRp7/I46tg+SSaaIVNDaFlo1id1G0KuxtCua5LiHOphfUOC7qDDXcvIleRxvd+kyT14ZYH7F2V3Hn43REn/eVJWoIFqRk4y6RQ+6o6OjkZubi7p16yIgIADBwcEmX6SOJtUDUTtEujYh7gIHPR5lLgZm3mv/wFtKrjLwcWbBDrbMESMy2A+V/bwkeVOXc6+VFvRpEoah0ZFoy/64ilG6o4PW1ajia7HHrCX9bXQxkMrEXhWLbUoxOfXLBHEF614eIO2qKjmukoWsFL0PJZRILQekKdoGAH7e0g26jRb+elclmiBQQ10najeoRaJz04YNG4YLFy7g3XffRXh4OFc7nFT9Wy0kxBjYsjqmLT8o6NitU3vB3WDAlWzp03++Hd0BLaf/Y/O4VjWlaUtFziG/yPGLBz1VFbVHWKAP3r1HG5NrrsLSxTrdZqtHd6RCVaMH36ruXpYUNTCai2yhKHZSQou61HeNFpz28pdw8KgH9hbkklM9C9fJdUP9sevsVYWjcVyfJuGStyrt0zQc0/84Iulj6pnoT4Nt27Zh+/btaNVKm+06SJyPHmyFKT/tN7ntvftaYlAreVcGSooklN+3IQU/gRcck/pIk4rvSt65R1zbDjXYWwSwWqAPrmY7NkMtNEOE9OuBdjXx8x5xrQ0fiamNb7fre0tWdp42ax4IEaRQ5ow9FaD1TM5uI8/2dt7P57a1KmNvYrpDj+EMhaYGtKiGVQdTBB1bWcHsN0fJuRbZ1EoFekesf76HZL3Xy5KqcKCzEJ231rhxY9y4oY3qduS4rg2q4tHOUSa3Pdg+En5e4mfnAzSwIvNEj3rwcHcTlCLTk/veRHu4Y221Q7DJVrqbnBMH1/McL4QUHlhxD5TWK8arJStX+XR+sX2BByqU2iy3/CJtDLp9nWAV11kE29HGyRXYyqJ7qL1jBWNHdqqtmW0nSrUtLNs1QahQifYTa4mURdp+Gh9T+m85BtyO8nLCgpCif6JZs2bhueeew4YNG3DlyhVkZmaafJH+NKomzey8FrYavNSvMQAgQOIUGa2x54NO/b+ONrStJd9+5GA/6xehd9QPtfkYDcyslq1/vgcWPhptd1xSuZShrVZEeiiu8v4DLdUOwamYWzl5tncDFSK57eOhrfDP5G6qxqBV3zzWHsMsFBGz5sp1YVvPqth4z1XDs33kfT4G+mpnEtZSirUWvHe/822F8pewBWH7KG3XZmks0dhES0QPuvv164ft27ejd+/eCAsLQ5UqVVClShVUrlwZVapo+w9IFZUvBNHWShEyIWktlbw9EKLC7Penw9qIrmirZw9GR4q+j/aHJ9K7v13NCrc1kSk9y9L5yrLUYqQsc2l0oZW80atxOBJmDbQ7NimY27NK1vl5eSBbpX6xjirbOtLbQ5kV5qgQP1japdGjUVWzLbkmW+naIeVFqiX3tKmJhuHOd4HoqIRZA9GzURieMVNgzpYCHUyoWSL3AoQ9PatdUeNq8n3WA8K2k/W51ZlHi7SwUGbNgfMZaocgOdHTZevXr7f4vX379jkUDCmvsq8XIsusHPxspUrqvFHtcMf/TP/+5fsg7n8jFr/uPY8XfzkgbaA2DG7lWoOBVwc2RYOwSixQYYM9vUwd8XhXx1sTvdi3sQSRSE+uPV+OCAtQNn1wQItqaGTH4Eqv+y8jq/jhZOp1ALBrtdIe79zTAo99s9tsYUMx7bdK6GnsVqeq46+viMraKzgVIePz30sjadZlGSXudeys7O24c/Kd/sjJL0KrN20XzJWTMxQsJGWJfrfq3r27yVfr1q1x+PBhTJ48Gc8995wcMZJM9r12J7w83EyqhFqbuTOX1udR7ngWkpLf4jEdzK72kG2TZE77k2LmuFaINguPaG3ADQB3Nq2m6PnmPNwO3nZcaOUW6HOl++OhrVHZzxNzH26LqgpNcHSpH4rqFgaO97SpIfrxxnWr62hIDrkhMMvB19MdT/UUvyJc3nejOzr8GFpQKLCbhJubAS011okk2N/59hJb4sj8wlA7MvaAm20Upa6yLaWyv5MCM8/jahqqxP6/+1rgwwdYGFspdk8R/vfffxgxYgSqV6+Ozz77DAMGDEBcXJyUsZHMSgoCGQwGs8Wb7KX0LO+YOxxfXdSDp3rWw7ejO6BrA2VXb51J32bKDtJIXlqf5CtJbXakwJ6teZz+zeV7TjeLCET867F297m29+Lyk4faVLht+7ReGBkTJfqxnu3dQNXV0OoCV3l7NwmTpD1cVScpHlVFx0XaciQoqGlNXQkyIqRy/lqOXfd7a0hzRGlwIlcKqWUyQP3MLJCsnaKd+g9D29fCfTa2xalFyxMr9hL1SXT+/Hm8/fbbqFu3LoYNG4YqVaqgoKAAv/76K95++220aVPxg5Jcz92txa9GOELKCQOtmtq/MV7o21j2dGltD2EcJ+d+bmd2rx0rjM7KnlTx8hlBYthKYZw7oh0CNVrdvtDO3O7WkZUr3ObhZt/A2c3NoPm9i1IxGJRrjyY3R14zais2ArVlzFga3Eo778eV7HzvuVtEfZC5D7e16xxqKTvJZ65GS4CP/a9RvdYHsYfWMlikIPhTbMCAAWjatCmOHDmCzz77DBcvXsRnn30mZ2ykUz6e7hjWwb60ITJvRKeKrbrkaJHKnWhkln6vfyXXuV4IvhzRTtCxJRdIg+2ciJyj0sVmt4ZVMa1/Y4cHq2kCK1CX+IBpjg5x1SyorFx5V5bF6lwvBJ3r2e5UYY8Abw/NZ/hIzd5MGy2oLHF1fWdc/S1v4q1uFFL/7rRA8BTVP//8g4kTJ+KJJ55AgwbqtucgyzI18uHjah8KcrqvbU2zaYdXs8Vd0JLjejSqipY1gvDpf6fUDkVRShXR0gODwYB+AlO6n761R7ddbfs6ewxQ6WJzyp0Nza42i+Xn5Y4cESsztqr/izWopX4v1u0xY3AztUMAAERHVVF0pToy2A9n07IVO58tbgr87Frp013Z1wuXMsVfi7gLnNB7557mFr8X4u+FK9n5os8tt7K9tKXuFS7FFhStc+bhg+BX7ebNm5GVlYXo6Gh07NgRn3/+OS5fvixnbCauXbuGkSNHIigoCEFBQRg5ciTS09Ot3mf58uXo27cvQkNDYTAYEB8fr0isaiq2M53P3tQ9ktffz3bFBxb6/HaRaSadLBsaHYnx3eupHYaiKnl7oH2U7VZnVNHzfRupHYKqhF5Yy+WFMr9/e4qw6Y1W9sj+NC4GPzzuWAtPqQcrzsbdzYBWGki/tfcl7i9w8GhtIu7TYdrc0lq20K2nuxOPIEk0wSOtmJgYzJ8/H8nJyRg/fjx+/PFH1KhRA8XFxVi7di2ysrLkjBPDhw9HfHw8Vq9ejdWrVyM+Ph4jR460ep/s7Gx06dIFs2bNkjU2Z/BS/8aSrGyQtAwGyxWxO9fnoFtvpNiP9WQPZQf9jhQBc2ZaGsRpJcOprI51xE3UmNv7WFaAHXtHlai4Pq2/Nlv8qaV+WCW4uRkqrPZGBIkrqtcgrJKUYSmu7I/fgZOWdvP2sFzToosLXgOZK8zmbLSSxSEH0Z9ifn5+GD16NEaPHo3jx49jwYIFmDVrFqZOnYo777wTK1eulDzIo0ePYvXq1dixYwc6drzZDmP+/PmIiYnB8ePH0aiR+dWEkkF5QkKC5DFplb0rUoNbRdjV6/pajvi+qc4qt0BYixNyDtG1qyDu3DVR96lZxfF+tXmFfJ6R87FVdduenrh+XuIuceqHVcKpW33JherTNFzU8ZZYay2mp+1a7WqZ30rRvk4wfo+/qHA06nmkcxQSr+bg6Z710bgaC3i6qrqh0k4evTqoqaSPpzV1q/rjgWhtVlOXgkPTCY0aNcJ7772H8+fPY+nSpVLFVMH27dsRFBRUOuAGgE6dOiEoKAjbtm2T9Fx5eXnIzMw0+dKTphGBNlcMpKTF3r1q0XO1VRJPiX175mTe4EQXmVo3pbvaITiFYBXbVKl5bimFi1zRdlYNwwOweExHdKwbIltFeTEZLs6wQhro42Exa+CtuyvWM8gtULfS97/PdccdDcyvxts7kebsGanv3tMCYQE330Na1HC+ySpJ1vDd3d0xZMgQWVa5ASAlJQVhYWEVbg8LC0NKSoqk55o5c2bpvvGgoCBERjpvFW49zZ7rgRSrmES2eDhx6hXZp76Kqbjnr92w+L1AlSrtPndnQ+x77U6T2+4UsCI9w8yFu1LsWcnXE61VGHcGviKeM9+O7iBLDD0aVbw2l8s/k7tj/iPRZr83Miaqwm1qd2MJD7Q8AfXzhBgFI9EPY5k/2mNd6mDNJO30NJeCqldv06dPh8FgsPoVFxcHwPy+VqPRKHn/zWnTpiEjI6P0KykpSdLH1xJre2WECnGS2XkpyNELtooTtkwQwt7+vkrinJV+9Wqs3IWiHhUWCd/CYOm1mnGjAO/db74IpByql1lhfaZ3A1Qp99kkpBK8PWnARhtvVbWCpZmMfULhWg5CeHkIv4SsFSxf32pX1ahagOBj5SqG+VxsQ1ke15xqQT4VWmY1i7D8mo0KkSYTs0cj6VvxBbvotZ0Ynu5uop7jeqDqoPvpp5/G0aNHrX41b94c1apVw6VLlyrc//LlywgPl2Y/VQlvb28EBgaafJFlz7l4dV65WZspVZqS1WSt7W+Uy5FkYVtJvD3c0KR6AJ7oUV/miEguc0e0Le0FKrW6VfW/5UaKLKiaVXxFFToqvy3q0c5Rpf8Wknrd+NbFmdYmgic4cbcDOdsXualc+Z6EkbPoVUnLRWvmjYrGLxZWjaXK5gwPcOw6TMjPQa5B1UF3aGgoGjdubPXLx8cHMTExyMjIwK5du0rvu3PnTmRkZKBz584q/gRUo7L5WfyCQu2vVDoDS79/Ocx5uK1i55pyp3Sz51KncXm4u+HvZ7uhe0PT2e+oEGVWcoL91UnZdRafPNTariwfW4W+Snz4QCtFX5dykOJCWuxjvDnYtB9v2RWthuG20+dLCgzma6zQYICPJwLtqLxuy/rne5T++7k7G5q0R9O7zS/2FFUz40Y+U9f16jUrhcEe7lTL5v1rVPZFtMzV4fMKHVsEeL5vI7xxl3MXQCNhdLE5sEmTJujXrx/Gjh2LHTt2YMeOHRg7diwGDRpkUrm8cePGWLFiRen/r169ivj4eBw5cgQAcPz4ccTHx0u+D1xr0jVQUVyLqXDkmA4iWwA5Qsp2aEr1mG4Qrkwa1ON31FXkPM6qW4ObkyVi90FzD555UrVDamolTVSIaioV8FKqD2+OmdZ9JendozpH4SmNrKY5+ttoUj0QkSJT0SN0Psnlyqy1FhSzZ11O5lp9cvVaHglXstUOQVa6GHQDwPfff48WLVogNjYWsbGxaNmyJRYvXmxyzPHjx5GRkVH6/5UrV6JNmzYYOHAgAOChhx5CmzZt8OWXXyoauyuKCvWvsBJI4ih1MUf6Un6vqtyqO1k14pLf3yABe3zLUqLnsx59Mqy12iEAAAy3hns1FC5oKVWKta2qxOYGllrsZX1fW+dt90PSa1Ld8mSbI8UFFz3W3u77lhdaybvC9di9bWtYPH5Yh0j4errDi0VPRUvJyFU7BFnJtyFHYsHBwViyZInVY4zlKpo8+uijePTRR2WMyrW1q22+H6cW7E9KVzsEh21+sZfNY7w9+aauJ+VrTtWs4mu1+rMWLHpMnqq3avjowVal/5ay5Zub4fbfNqKyL2oF++FCurb/rlKpHqSNVcaAWyncz8fKm2b9+1NdcPcXW0v/b8/eY28Pt9J0eAC4o36o1Yt4ADB3GrVbIlUykzZfy8FtNuk5+Q7dn27z8XRDbkGxpgtHursZ0LR6oOCaKkJJWVX9173nseCR9hi1cJftgwHc06YmhrSuIXlxXTlrKJAyeMVOduM6rLyErHT7e/FNWE/Ss00vKOuHVUK/5tUqVGTVEq1XD/3+8Y6Cj61ZRfp99+uf74EFj95cVVk3pRvCA30w894WeHtIcxv3VM/TPeujY51gBPp4oG6oaeG3OqH+iJTg92SrqrctuSL3UZYUX/Tztrw61qJGkEMxARULvkmReVI1wNuuC3SpqjPbq5K3Bw5Mj5X0MeuEiv+ZRsXUljQGZzFv5M32WloqyGqO1mvm5RcWo1u5zM0bNia85Ohm890Y55kAt8TZW+9y0E2yuegiKz3kHJRIoza3uvrliHayVdJ2BV3qh6JL/RDVzu9mAHo2CsORGX1RP+zmBEVUqD9GdNLuQKBRtQDMfyQaa6d0N8lkeKlfY6x/vgeC/ByfBHK07V91kQOFqFuDNWuD/Q8eaGX5mzpRNmX1rSHNMbV/Y1kKtQnloYHeie1qK1dvRApiJ5Ts5ed1cwKqtsxFPh2tEq7kc8iezBRzWZ25BcoXbGxbS7vZpVJx9u0pHHSTbF7q11iR8xQUVbzKmtxHud6RYrWs6fhqC5GU9F4/QAsZH34aiEEoH093BPp4IjzQxyQdWMoCmGGByu6BH9GpFl4Z0MRqwUcx19vfje5gs+KwkhWJSwYLbmWu2iIq+2JC93qyrKpJ7bqZQnBKqSLBJJKUlMpsah1ZGd881t6k/Z4cHB0z5ynYccCeCQKmdStHym1fWsRBtxMa302Z6sZXs63vverTNNzsDKHUaZcBZmb5n+qp3erpnw+TrvXWlet5kj2WNc7ca1aMcJlXw20VU5JLbNNqqpxXz0pSe0sqSNvylobSzbs1lK47gCXDO9hu92ONt8giSgE+nhjbra7D7c7qVfVHeKA3ujWsise61LF43D1talj9vjX2VFof0qYG7mtbE3dI2NlBSUIrjJurFO2oKDtS1uWkVFVuN4MBPRuFOVSQTA7lFx68Bb6HCiV1y0ah7/FEtvCZ5ISm9r+9wvze/S3NHrP/DWn3YYlhLe2yfDE8IWqZaS/i4SJVI5WaIS77nHJlbWQeFI+5w76LeEcFanhPuRCjYqIEHVdYZPp6Ebof/N42NSpcKI/rVheLHmsvuJDYg9Hi0ubknPC3p0+5WM0d3D99V6sIiSIR58dxMVj59B2ynsNoBP6Z3E3UfUIreePDB1uV7iW157NSTe4CV+NrSjxgGtu1Dh4R+P7gTMZ3r6vYqqGPyPeTe9qYFg0MrSRtVsw4GwtPu17uLerxnjSTAeTDIrZkBz5rnFDZVLN+zc2vYEmS3iTD+7nY1Q3gdt9dZyMkDSrjhvo92eUSUVl7xV+spXHqNSnqx3Gd0LS6toul2SJ4T7fB6n8t+mho6woXsL5e7qIq5Iod6GppZVwNaqV0Vg3wVqTwlL3vFx638su1XHxRS14Z2FTyQR2Z8hS5EjywXLvGp3pJ2/Pa1mRDmMjXd92qFVvzNbXS6swctbLYSFs46HZyvp7uqBXsp5uKgPakBTnrHpDKfrar4motbUxKz7K4mOwm9qqPTnXVK0KmtIbh4icXHu7oWJq0vR7uKK4Qm1LbipzVgkeibR4T2zQclX1vvi/3bmJ/SyIpPrIcLV6lVfa8Rm2p4q/cBEVJ8TKp1K1qmhqfJXBv/I4zVyWNwxpbWw1t0WOBMLF1FNro8GeUS9cG+twiIwUOup2cp7sbNr3YE4NaqpOqx6JhFVlraVPik4dayx8IubwpNnoaK1HRXUnlV7yETNhpuQq5VAa3isAAC1lR9nBkQKqW7g1tZ0zFNquGID9PnHi7v2qfqc5ufHfpJ4+aRQThQwUq14f4e2HrS70kfczyq8JC7U9KlzQOUpczpbN/NbKd6EwBZ8GSfE6qYXglkz2IBUXKtzcAgOdjG+GbrQmqnNuat+5uptq5hRQNaRAmbLZf7qK1Q1pHON3AS01SbQdoEFYJJ1OvO/QYP47rZPMYMenTeiRkhaXQTHcEewV4ewheqVKS1JN8T/WUNl1UK0q2vEhdWEnNll9aEh7oLVv2Vi2Z22ZFBPlg2zRxe4Xt8bSTvrZcQdtaVSpkLgh1aHpfiaNRj5+XB1rWDMKR5Ey1Q1Gc80ydkIlfnuiM78fevqj2lzjlSSh/bw+TvqJaMVLjhVXyBU6SyJ2CPfuhNnipfxNZz+FKii30Lq50K/tB6AWnpQKJYjSNsD3TrGRLJDUIGTxdzLgh2fks1dgoL9yOdluOtCwzGAyStp3KFDm5NE0nhRrNFe0UI7SS+S1DT/QQPpAqyR7TSrFQpSpx003P97WenVRCb22uXGHi6ecJMXjfzs9urbzeyTH8KzqpQB9PkzddfxXfgC1daJBlHgL3693duobtg+ykVvVgVzS4VQ28PqipoBRXJTlzzQA1CB3Xbp8qfsVsRCd19p6X1cRMyuB3ozvYvJ9S+5MdLfhds4pjg+7tZlZCH2hXU1QLsad61sfKp7toZlAldLImv0j6VmByEruifDEjV5Y47P07K7mPXQrjFW5LunSs7UyvElItWrm7STu5SfrDQbcL+t99LRQ938dDWyt6PmfQTMAqpNw83V3rw0HqXqFi+Hq5Y/QddRTtB+paf13gtUH2rdqrkaljT3HIEA1UaG5bq3KF24T0zW5j5n5yuJZjf8EnsS2+ysrMvbmlwNzvIiVT3GDNx9MdLWtWtjsWOVkrkJR5Q3vbKqyp7Cdu0CrXir+flzvubBou+n4d67hOgczyOtYJtnlMTD3hvx+uMktPK5OGSuMzyQV1qa9s5cCOLlQdWSqcDVXeG3ept89fKa8MuL1VIMDn9kVlvoT7lrXmkZjaSJg10P4e6Hwp2tS7cRge7RyFkmeR2PevdrVtXyRLoWqA/RMTUlfVLulO4Uzp2Y93tVwELTpK3erNeq72bmn7hbUJQR3/uACAPk3CRGda/TwhBuumdBP8Wh3U0r4idVLIK1SnzpIaqpiZwLLVS91ZcdDtIgLL9PT0d2DvH7kOsfsylbBuiv2rTbb0bGy9aNhsMxkbqyZ2FXWO8q37Kivca/fetua3IwjdzqBH9cIq9lgVo20kW73YsuDR9pg+uBk8bz2PlH5eC1XPTL9dtQT5eqJjnWBM6KFsWq1aBqu8XcnanuGPhzpe2dxbRHXpYpH7HMz1iQbg1M+d4Xa0amwfFYz6AovQqi2vUF/bLRzx21NdKtwmtle6s+Cg20UMaV0DM+5uhs0v9kQVf+6xdmX3ta0p6Dh7eqbLTc0P1CFtKg5Yawbf/h3l5Nv+EB1W7kLiORstu5TixGNuhyYZfT3dESQyzVTrlozpqHYIqrJnu4A9he2scXMzwMvDDcvGx+iyR7E9tJy9dZeZ9m9iV1nfuru54GPTrgvf5mBtRbROqH2VsPWgWwNt1Tch+9UOcd7nqVgcdLsIXy93jIqJQqSD1VdJ/z58UNisvtr7mK5mq7fSbq4glC1CJim8PUwv5Ox9PQoZ4NPNv8lAB1IIwyQebGnBHVb23VJFv0yIwfePCy+6ZE7ZFPIWNYLwgkYm2+i28jUfGojMkBFTeDRdRG0BPawIju0qbuuOrQmYVwc2Uf36o4QWtn+EObAtRmvMpZq7Em08q0mXzl8V3kqnpEDUXxPvkCsc3dDCm7geWPpcjgzW3gq80k452KO7TxPn7r9dYsGj0azArrKSFlcA8FRP9dNhhbZjLBEdFYz6Dm5R+PDBVhjS+uag7I9n7kD/FurtJSXzxtxRB9881r70/3KuzIt5bO3mB9wmNGPryR718Nbdzcx2tOld5jNJSDtLpRx9q5/aITiFJ3vUQ6CPh9kODq6Eg26yWyURfRU/GdoaD7SriWYRQVaPC3aB1HetzODakpOvzWqzHm7mf3/WepbH1A3B0OhIuUIijXL0/aTAhYrdyKVsu8rnNbDCq0b9ggEtqmP2Q20UP69SSooiOVqRWO0K5z0bKTMZ6abhVHt7CP1xIir7YmRMlNlJh8bVAvGEE+9Rd3Uv9muM/W/EuvwkOCtqkSL6t6guaHZfzxVGxXjnnuZ4ZcUhtcOwqqoGWhCJUTvEcqr29493FHxhIIYa7aQAYW2YCAgLcCw1093F2uY5ytaEotjVw2EdamHprkRHQqqgTqg/TjqYKUKmptzZEM1rBKFNZGWHHkfO7RxCn3tuBiC2aTXRxc60ppeNwqBqsDUp43drQOau8UmJKCvXGnK44STbybRc10EpvHIjUoGnhdVaLfHTaB/F4R3EVzV1czPI8oav1qxtk+rSFpRrVsN6BoqrCvbX18ST2h7tHIV72tRAo2qmz89x3eoiIkj8BMjLA8y3SnLEzHtbSP6Yrs7H0x2DW0XY1V++LKm3XpXdlx1kpaJ+2ZXnbVN74+OhrRHoo++9p/2a628Lw/COtTChez200XhxwWXjYxQ9X1aeNrMOSTztX/kTkUUBIlL8tfTY9qh1q+jY0A7yp4n3aFQVdyjcz14MRy9KAspdULatVQUBGp1kkVtJvQlyXGSwHz4e2rrCZNS0/o2x4YWeAAAfEa2V5BAdpUxPcBIvW+ItTQ3LTP5YWrj29XQ3mSyoFuQDXy93zb0vfDG8Ld4c3EztMBxia947pJI3pvZvrLnffXnhChe3UyujjqTHvySRCqRKXXPm/srl9WikXAuRRuEB+PqRaFke21KvbCVU8fPCuG51MblPwwrf89T4hY5Yr5erRmzJlyPayhzJbU1vVcV3lW00JQwGQ+mF9BfDTX/f97ez3cKwfNV/0qc37rL+mgz2k6+mSyVvD/h7u+ODB0y7d/h7m39uiWnHZU8Wh1gDW1bHI52jZD+PnLSY8g4AntxGRApxrqssIp1w9WISzuhSVq6g4/o1qyZzJJa5uRnw8oAmqCVgT5q5gbmejL5DWBubXo3DsefVPjJHc9OITrWxelJXRFTWfhsguZS/8G5tZR+wv5cH7mpZXRMF2MhxtoY2vl7yfS76ernj8Jv9KkzyRFnoIexqE2NKKJ9hpTf3ta2BDx8Q1nKVyBwOuolU4CfjxQVJQ2yFWbEpYFpL3y/v2T6Wq8FrjaP79UMsFA2Uuj+qh7sbGlcLxMRepr/bR3W+giWGmL+Vm5sBnw1vixY1WXPAGaRdF96fWin/u7+l2iGQTnz4YGvcJyAzh8gSDrqJVCBkpZHU5eXhhl8myFcw5cke9WV7bFf3RHfHWs98N7oDagX74bWBwlLUxXqgXPu66YObmRR9InJGV7LzZHvsUTG1K9x2NDnT6n0e7RyFelX5uiNSw8CW+iv25yjdDLqvXbuGkSNHIigoCEFBQRg5ciTS09MtHl9QUICXXnoJLVq0gL+/PyIiIjBq1ChcvHhRuaCJLGhcLVDtEHTL0opyKwfb1ZjjSkWXhOyt1YuX+jtW9bpbw6rY9GJPRSfHSgoFEpF45SvmA8CZy9lW7/NML21MfM55WLm6EnRbSWWdomJ9t4fTq/KdaFyhT7tuBt3Dhw9HfHw8Vq9ejdWrVyM+Ph4jR460eHxOTg727t2L1157DXv37sXy5ctx4sQJDB48WMGoicTrUj9E7RAAaLdipo+nOx5qf3OlsGuDULx3X0skzBooyYrFiE7i25E5i6n9GmP/67Fqh+GymkXcnIhb+Kg8Bfy0SulKwKQePy/5ttT0aRIu+j6WtpUobUALyyt+VSXe4kK3FRXdHGxzzK2OLhruECMXbW8qvOXo0aNYvXo1duzYgY4dOwIA5s+fj5iYGBw/fhyNGlUsshIUFIS1a9ea3PbZZ5+hQ4cOSExMRK1arntx7ep+fULZHotiaaW/Zn8rFwJqm9q/MWqH+GNct7qSFry5o34oluxIREil21V0X+jbCHVFVLJVSu0QP5y7kiPZ47m5GRDk54mJveoj2F++KsJa1TC8Ek5cuq7a+Z/sWR89G4c51A6uTa3K2JeYLl1QCuhQx3WySVydnKXJ1Jy8kbMwakcdvD6sdRfwcndDflGxgtEIFxnsq3YI5GK0uZRVzvbt2xEUFFQ64AaATp06ISgoCNu2bRP8OBkZGTAYDKhcubIMUZJUAmUuMJV4VbqBihw2n7gs+Fh7C0j1aFQVVfwsVxIdGh2JShru21zZzwtP9KgneYXZO5tWww9jO6JLvdszsE/1rC/pBETJ38zRdm+/PdlFinAqmBLbCI92EVb525moveLq4+nucP/1gRqeKLPEwRp4pCNZudL24daKF/vJV13f0SKRaqtbVXsT1iVG31EHIzvVRm3W2NGErNwCtUOQnS4G3SkpKQgLq9jfLywsDCkpKYIeIzc3F1OnTsXw4cMRGGh5P21eXh4yMzNNvkhZEZVdY/bx4Y6OZ1vYO+ic+3A7/PtcD4vfz8pz/jc/c9zdDOhcLxRuIn6vYtPwO9cLwQPtauIeB/t1V3HB1Wgi0q9CJ83j1Up2GolTPcgXbw1p7vAEOEnDFeqaqDronj59OgwGg9WvuLg4AOZn+4xGo6BZwIKCAjz00EMoLi7GnDlzrB47c+bM0mJtQUFBiIyMtHo86Y/YVlByaevgqpY9Zt7bAsDNnqXWUogjXeDNTyqLHmsv6nh/bw+8/0ArhGpkPyGZmjeynaLnc6YCdvZw18j7Mckvt7BI7RCISEPsqcWgZ6oOup9++mkcPXrU6lfz5s1RrVo1XLp0qcL9L1++jPBw63+wgoICPPjggzh79izWrl1rdZUbAKZNm4aMjIzSr6SkJId+RtIea/uPlGTpWlPqlOmyhnVgLQOp1b/V6qmKH1eenUHD8IpVkOX0wQOtFD2fFpTNDvHX8DYWktZfB5LVDoFk8vtT8mx3Iuf24YO3P/8OXnD+zGJVP+1CQ0MRGmq7el1MTAwyMjKwa9cudOjQAQCwc+dOZGRkoHPnzhbvVzLgPnnyJNavX4+QENtVob29veHtzRUoIVrL0KKJ1Fv5alo9EEdu9TW9cj1flRj0qGqAN6bc2RAPRLv2iqXaGlcLwLGULLvvv/lkGgDnWI0LreSFNA2/hn8c3wn3zhFej0Vq79/fEi/8ckC18xNJZUjrCPwWr34rXE+NdjtxRGMzbehIWkG+t2sLdamnjc49ctLFq6RJkybo168fxo4dix07dmDHjh0YO3YsBg0aZFK5vHHjxlixYgUAoLCwEPfffz/i4uLw/fffo6ioCCkpKUhJSUF+vnYvRvRk1n0t1A7BKalV0Mnb0w1/P9sVgL5TPlvVDFL0fAaDARN7N0D1INeoRaBVD0Y7thUoIujm68459pVp+/UbFaJucaUHHHyukGvQw6CrY11tD1T0sDjToY753+GixzooHIlr00oLPznpYtANAN9//z1atGiB2NhYxMbGomXLlli8eLHJMcePH0dGRgYA4Pz581i5ciXOnz+P1q1bo3r16qVfYiqek2VhAeyv6mzkTG1Xwpcj2uHTYW3UDkMx47rVVTsEp7F0XCe8c09zWXsJk3b4ytjmiczrECVv+6v2UaZ1UppWN7+dsJ7AitqfD1f3s6R6kP6vsV4e2ETtEGx61UKM1Zzg90/aopuri+DgYCxZssTqMUbj7cqYUVFRJv8naYzvVhdfbTqjdhi6teuV3mqH4NT6Na+mdgiKyivQfyq0VtQO8UdtlVdgSTnhgd5IkLDPPdnWvVFV7Eq4avH7jk769mkSjt0J12wet+ixDkjNyrN5XG6Buv2lP3OCCeRAH8utSbXC39sD797TAnPWn8L59Btqh0NOTDcr3aQN0wZof9ZSy5gdYL/8QnUvgLSoGlPadeuO+qEY0ck1Cxt6uN8cXE3sVV/lSEhLHomJUuQ8kcF+aFfbdveQgiJ1P3OiBWQG3MjnxKsUhneshS1Te6kdBjk5DrrJab3Qt5Htg1yItRZhehCm0l53IjksHtMBbw9xzboYgT6e+PWJzniyp3qD7s71bRdxJeV4uhsQ28y1MpXKGtrevjoDEZW1/7lYtlgWkSvjoJuc1tiu3O9KRNpkkLVYofa3VrWrXQU+Ku6rtrSPk0gN/7uvpdohyGbl010wf1S02mEIEhXiDIU0Sas46Can5eVh/umt9cLcNSorlzL82bA2CA+8WTGyZQ1lq36T4zx0XviOpFVQdHOwnZlbqHIk2ufn5YE/n7lD7TDIBRW7WL2h2iH+uLNpuNphCMKK5SQn3RRSI5JKF42nFVZRMA38rlYRuKtVBHadvYqmEYG4yCIiunJP2xp4Z9VRtcMgjajsdzONk1MxwuRwPyypILSSvrd6ObOoUBbTVJqnu6F0wtjZcaWbXIq3hxsqeXOuqbwOdYJRydujdOW0ZPWbtC3UBfpaijW1f2O1Q1BNVm4BAKBe1UoqR6IP7HDi3FpptEc0C6oS3TapT0O1Q1AMB93kUga0qK52CJpWJ9QfHzzQCo+z/zPplJLbM7TG7dbemfHd+folenmANifgujesKtljZdwokOyxSKOYuuQ0OOgmlzHj7mZ4557maodh1bO9G6h6foPBgPvb1dRFb00iMs/DjR/tQnirWMiN5Beg0c8xNwu1OPo2E7/vubhMssZ4FSfLtV4rR4z2UVXQsqZ2atxMdqGVYGfHT2ZyamXTpGuH+MPPSzup5T0ahVW4jYWxiIiU4efFQTdpx5cj2pX+e8wddUTfP8BHveubBmHOs6Vl8ZiO+Gl8jNphlHqiRz21QyCJcNBNmpN2PV+Wx/V019aAVqq+2eOYCk5ERBrHeirWlbQR9PV0x2uDmoq+f6e6IQCAEAWLsZbwcK84nAhUcRLAET6e7qq2M3Q1vrd+1x4au0aXgz5fEeTUsvOkb3cztX9jtI8KlvxxtaBd7Spqh0BERGTVfe1q4kZBEWb9fUztUDTjjbvED67NmXlvC0RHBePjoa1QN1Qbq85sXUhC3NeuJtJz8tG5XojaociOK92kOXmF0rdxmdC9HjzNzMQSEbmKXo0rbmkhUkolbw9M6M5U2bLMXZe0tqPqesnOtHva1NRM1fbIYNctaknCBfl6YkpsI3h7OH92AVe6SXM83d2QV1isdhi61K1hVWw6cVntMCTB/ZZE4tS7ta+yZhXzF7sLHolWMhwiEmnho9FoXC1Q7TAk8UxPdQvDOoNJffg7dCZc+iPRYuqG4PlYbVRT7G1j5aZFDe1UoFRCYZHlyQq97ae7p00NtUMgHSkpIuTKkzU9GlbFzpd7W1zpMjhTiWEiJ9SrcTginKTtYYwLpAvLzZ6sB9IufV2FkyYsHddJ8XN+OaIdJizZU+H2Z2y02Hr3nhYY1iFDrrBE6dogVPZzuFuofj60fSTubhUh+/mlpNV2L6RNd7WKQG5hMbpJ2ANXbwwGA8IDfdQOg0i0sq2vtEKJvdEFVibKhSiZZPTVUGeWEpZaoxG5Ku29SsnlFUr46RsW6IPeGrkI7dZAncHA64OaYrQd7UeI9MTH0x0jO9VWOwwiskORBkfdQX7yT/zWq+rYwL5vs2p4bVBTxDYV3+NbbhFB2rj2ItIKDrpJc4qN2vvw1QtvD+4YISISwoMrcZpRNcBb7RBU4WgGnI+nu109vZXA7SxEpniFTpoTHuA6s6Plr/nsKSBX2ff2bPwTPepX+H7Lmq61r52ISIg6of7wv5WeywGCchpXC6hwW1ZugQqRqI/POyLXwZVu0gW9FQGzV7C/l+j7dKhzu/+4uZ7d0U7an5yIyBEGgwFxr96Js2nZFuthkPTczAw0awX7qRAJEZFyuNJNmtPTTEXy1rUqKx+ICuyp9smZctd2d2t9FcgjdfRtpr09n1rg6+WOphHO0aKJiMjZONN8KAfdpDlv3NW0wm1O9JqzqmF4xbQ7oZxxf+IPYzuqHYLmdS4zUdOxTjAahstfcZf056uR7NFNRPJpH1Ux047IUZX9xGeAahUH3aQ5Pp7uGN+9rtph2KWkV7BQ5UvG2Zvi+PnwNqq0cpObr6fr9lwWKuPG7b2Qy8bHoD23E1A5d+msXSCRPRpwwlFVbc1sbyOi2zjoJk3S62DrgwdaWfyet2fFl5tUhdoHtYxwysFW2Z7DdzZheqw5zjQLTPK4kV+odghEsuvZqOLWNCLSt9aRldUOQTIcdJPuBPnK3zvTXmHl2p680LdR6b/vbl1D6XB0L6Kyb+m/W7AKu1n3ta2pdgikcWVfR0Rqyy8S36VDCNY3Ib2oxh7mgs26twUWPdZe7TAkwUE3aVKNWxeJUSE3K5qW/SxtpqOiN02q396jreXJAtIvdzdD6esFAKoF8sOciLTLy12+S8+HO9aS7bGJpBIW4MOK/QKFBfqgh5NksXDQTZo0pE0NLB3bCUvHdcKMu5vBz8sDoZW8bd9RQ0bF1EbdUO4xI/lVLZNh8dgddVSMhLTIw40f9aQdVfzlm4DuI/E2pBY1mGFF8hBSwieQizVORTefxNeuXcPIkSMRFBSEoKAgjBw5Eunp6VbvM336dDRu3Bj+/v6oUqUK+vTpg507dyoTMDnE090NMfVCUD3IF6NiogAAXz8SjZn3tlA3MBFm3N2cvV9JEe/e0wITezcA4Do97Um4UTG11Q6BSJc+HdZG7RDIRS0e0wFtnGg/M+lo0D18+HDEx8dj9erVWL16NeLj4zFy5Eir92nYsCE+//xzHDx4EFu2bEFUVBRiY2Nx+fJlhaImKbWOrIxhHUxTx3ILilSKRrtacu+zy2kaEYgpdzZUOwzSqBpVuKebyB6e7rcnzueNbKdiJORqujaoyjoFTkYXSyJHjx7F6tWrsWPHDnTseLNv7/z58xETE4Pjx4+jUaNGZu83fPhwk/9/9NFHWLBgAQ4cOIDevXvLHjfJo2Qlb2r/xrqp2F031F+xc303ugP+PZqK537er9g5iUibYpuGw4MZN6QhBujz+RjbrBpa1QwCDIC3hzt2nb3KyU4iEkwXg+7t27cjKCiodMANAJ06dUJQUBC2bdtmcdBdVn5+PubNm4egoCC0amW5rVNeXh7y8vJK/5+ZmelY8CS5F/s1RkRlX4zvVlc3s4DNFNwXVtnPC+3YL9PlBfp4IDOXraJc1W9PdUElb3fUDwuwfTCRgsZ0rYMtp9JMbqsepI9sjKXjOsEAAx75ZhcAYIydNTTqV62EbLbyI3Ipuhh0p6SkICysYuW6sLAwpKSkWL3vn3/+iYceegg5OTmoXr061q5di9DQUIvHz5w5E2+++abDMZN86odVwvTBzdQOg0hXItiixKU4U29Tci49G4UhwMcDWWUmBd/VSb0WP6+bl833ta2B3QlX4WlnJfal4zqh2GiUMjTNGNYhEh3rhKgdBpHmqLqne/r06TAYDFa/4uLiAJjvv2g0Gm2udPbs2RPx8fHYtm0b+vXrhwcffBCpqakWj582bRoyMjJKv5KSkhz7IYkAeDK9kxRWK4TtSIhIm8pvuaqhs17yQ9vXwsm3+8PLw77L6KoB3gh30vaO97SpiSFtaqgdBpHmqLrS/fTTT+Ohhx6yekxUVBQOHDiAS5cuVfje5cuXER5uvT2Ev78/6tevj/r166NTp05o0KABFixYgGnTppk93tvbG97e+mpNRdoVHuiD2KbhGN+9ntqhkAuZfldTdK4fitiPN6kdChGRYuRaPfb1dK9wm4eM/caJyPmoOugODQ21mupdIiYmBhkZGdi1axc6dOgAANi5cycyMjLQuXNnUec0Go0me7aJ5OTl4YZ5o6LVDoNczKNd2KubiFxPlExFS/s0lbb/NxG5Hl1M0zVp0gT9+vXD2LFjsWPHDuzYsQNjx47FoEGDTIqoNW7cGCtWrAAAZGdn4+WXX8aOHTtw7tw57N27F48//jjOnz+PBx54QK0fhUhRoZW81A7BYTF1Q9C4GotBERGRdfWqVkLD8EqoyTZ5RKQxuiikBgDff/89Jk6ciNjYWADA4MGD8fnnn5scc/z4cWRkZAAA3N3dcezYMXz77bdIS0tDSEgI2rdvj82bN6NZMxbhIm3oWCcYO89ele3xuzaoKttjK+Wbx9o7bcEZIiKS1upnuyG/qFjSxwz00c3lMjmBlwc0VjsEkoFu3kWCg4OxZMkSq8cYy1yY+/j4YPny5XKHReSQqf0b454529QOQ9N8zOylIyIiMsfNzQAfN2k+NyKCfPF0z/p4uFMtSR6PqESzGkFIuJJj9nvjurEOkDPSRXo5kbOyt92ILe63qqVXDWBRQLqpfZ1gtUMgItIVNzcDnu/bSDd9xNXUMOzmNrBgf0+VI9GHNwc3w8JHK9b8cYZtgWSebla6iZyRXFnTNav4YsbdzXBXywh5TkC6M2Nwc7VDICIiJ3VPmxpoFRmE+mGswSJEaCVv9GocjqgQP5MV71n3tlQxKpITV7qJVFTZT54ZYYPBgFExUajizxlTAqb1b4wgmZ5rREREbm4GDrjtsODR9mqHQArhoJtIRSVp4ERyqh0iTxsdIiIisl+9qpXUDoEUwkE3kYqqB/moHQIREREREcmIg24iFRkMXOkmIiIiInJmHHQTERERERERyYSDbiIiIiJSxdT+jdUOgUgzAn1Z9NRZcdBNRERERKoY362u2iEQqcrL/eZw7JOHWqN9VBWVoyG5cNBNRERERIr7Z3I31jYhl9exbjAAoEfDML4enBgH3UQacV/bGmqHQEREpJhawX5qh0CkujaRlQEAHu4ccDszD7UDIKKbPnywtdohEBEREZGCnupVH/2aV4e/N4dlzowr3URERESkmIc71Yaflzs83LiyR+Tt4Y6mEYFqh0Ey45QKERERESnmwehI3N+2Jtw46CYiF8GVbiIiIiJSFAfcRORKuNJNpLK3hzRH1QBvtcMgJzSgRTWsOpiidhhERERELo0r3UQyuLeN8ErkIzrVRt9m1WSMhlzV4FYRAICwQE7qEBEREamFK91EMgjw4UuL1BfbtBpWT+qKRuEBaodCRERE5LI4MiAiclJubgY0rsaKqERERERqYno5ERERERERkUw46CaSQZHRqHYIRERERESkARx0E0ko8WoOAODnuPMqR0JERERERFrAQTeRhDzcbr6k8gqLVY6EiIiIiIi0gINuIgn1bhIGAJjzcFuVIyEiIiIiIi1g9XIiCfl4uiNh1kC1wyAiIiIiIo3gSjcRERERERGRTHQz6L527RpGjhyJoKAgBAUFYeTIkUhPTxd8//Hjx8NgMGD27NmyxUhERERERERUlm4G3cOHD0d8fDxWr16N1atXIz4+HiNHjhR0399++w07d+5ERESEzFESERERERER3aaLPd1Hjx7F6tWrsWPHDnTs2BEAMH/+fMTExOD48eNo1KiRxfteuHABTz/9NNasWYOBA7nXloiIiIiIiJSji5Xu7du3IygoqHTADQCdOnVCUFAQtm3bZvF+xcXFGDlyJF544QU0a9ZM0Lny8vKQmZlp8kVERERERERkD10MulNSUhAWFlbh9rCwMKSkpFi83//+9z94eHhg4sSJgs81c+bM0n3jQUFBiIyMtCtmIiIiIiIiIlUH3dOnT4fBYLD6FRcXBwAwGAwV7m80Gs3eDgB79uzBJ598gkWLFlk8xpxp06YhIyOj9CspKcm+H46IiIiIiIhcnqp7up9++mk89NBDVo+JiorCgQMHcOnSpQrfu3z5MsLDw83eb/PmzUhNTUWtWrVKbysqKsJzzz2H2bNnIyEhwez9vL294e3tLfyHICIiIiIiIrJA1UF3aGgoQkNDbR4XExODjIwM7Nq1Cx06dAAA7Ny5ExkZGejcubPZ+4wcORJ9+vQxua1v374YOXIkHnvsMceDJyIiIiIiIrJBF9XLmzRpgn79+mHs2LH46quvAADjxo3DoEGDTCqXN27cGDNnzsQ999yDkJAQhISEmDyOp6cnqlWrZrXaOREREREREZFUdFFIDQC+//57tGjRArGxsYiNjUXLli2xePFik2OOHz+OjIwMlSIkIiIiIiIiMmUwGo1GtYPQsoyMDFSuXBlJSUkIDAxUOxwiIiIiIiLSgMzMTERGRiI9PR1BQUEWj9NFermasrKyAICtw4iIiIiIiKiCrKwsq4NurnTbUFxcjIsXLyIgIEBU6zEllcywcDXeNfDv7Vr493Yd/Fu7Fv69XQv/3q6Df2vXYjQakZWVhYiICLi5Wd65zZVuG9zc3FCzZk21wxAkMDCQL24Xwr+3a+Hf23Xwb+1a+Pd2Lfx7uw7+rV2HtRXuEroppEZERERERESkNxx0ExEREREREcmEg24n4O3tjTfeeAPe3t5qh0IK4N/btfDv7Tr4t3Yt/Hu7Fv69XQf/1mQOC6kRERERERERyYQr3UREREREREQy4aCbiIiIiIiISCYcdBMRERERERHJhINuJzBnzhzUqVMHPj4+aNeuHTZv3qx2SGSnTZs24a677kJERAQMBgN+++03q8dv2LABBoOhwtexY8eUCZhkMXfuXLRs2bK0x2dMTAz+/vtvtcMiCc2cORMGgwGTJk2yeAxf387rwoULGDFiBEJCQuDn54fWrVtjz549aodFdoqKijL7Wn3qqafMHs/XtvPKysrCpEmTULt2bfj6+qJz587YvXu32mGRBnioHQA5ZtmyZZg0aRLmzJmDLl264KuvvkL//v1x5MgR1KpVS+3wSKTs7Gy0atUKjz32GO677z7B9zt+/DgCAwNL/1+1alU5wiOF1KxZE7NmzUL9+vUBAN9++y3uvvtu7Nu3D82aNVM5OnLU7t27MW/ePLRs2VLQ8Xx9O5dr166hS5cu6NmzJ/7++2+EhYXh9OnTqFy5stqhkZ12796NoqKi0v8fOnQId955Jx544AGr9+Nr2/k8/vjjOHToEBYvXoyIiAgsWbIEffr0wZEjR1CjRg21wyMVsXq5znXs2BFt27bF3LlzS29r0qQJhgwZgpkzZ6oYGTnKYDBgxYoVGDJkiMVjNmzYgJ49e+LatWu8YHNywcHBeP/99zFmzBi1QyEHXL9+HW3btsWcOXPw9ttvo3Xr1pg9e7bZY/n6dk5Tp07F1q1bmZXmxCZNmoQ///wTJ0+ehMFgqPB9vrad040bNxAQEIDff/8dAwcOLL29devWGDRoEN5++20VoyO1Mb1cx/Lz87Fnzx7Exsaa3B4bG4tt27apFBWpoU2bNqhevTp69+6N9evXqx0OSaioqAg//vgjsrOzERMTo3Y45KCnnnoKAwcORJ8+fQTfh69v57Jy5UpER0fjgQceQFhYGNq0aYP58+erHRZJJD8/H0uWLMHo0aPNDrjL4mvbuRQWFqKoqAg+Pj4mt/v6+mLLli0qRUVawUG3jqWlpaGoqAjh4eEmt4eHhyMlJUWlqEhJ1atXx7x58/Drr79i+fLlaNSoEXr37o1NmzapHRo56ODBg6hUqRK8vb0xYcIErFixAk2bNlU7LHLAjz/+iL179wrOQuLr2zmdOXMGc+fORYMGDbBmzRpMmDABEydOxHfffad2aCSB3377Denp6Xj00UctHsPXtnMKCAhATEwM3nrrLVy8eBFFRUVYsmQJdu7cieTkZLXDI5UxvVzHLl68iBo1amDbtm0mK2DvvPMOFi9ezIIcOickvdycu+66CwaDAStXrpQnMFJEfn4+EhMTkZ6ejl9//RVff/01Nm7cyIG3TiUlJSE6Ohr//PMPWrVqBQDo0aOH1fRyc/j61j8vLy9ER0ebZKRNnDgRu3fvxvbt21WMjKTQt29feHl54Y8//hB1P762ncPp06cxevRobNq0Ce7u7mjbti0aNmyIvXv34siRI2qHRyriSreOhYaGwt3dvcKqdmpqaoXVb3IdnTp1wsmTJ9UOgxzk5eWF+vXrIzo6GjNnzkSrVq3wySefqB0W2WnPnj1ITU1Fu3bt4OHhAQ8PD2zcuBGffvopPDw8TIowWcPXt/5Vr169wuRZkyZNkJiYqFJEJJVz585h3bp1ePzxx0Xfl69t51CvXj1s3LgR169fR1JSEnbt2oWCggLUqVNH7dBIZRx065iXlxfatWuHtWvXmty+du1adO7cWaWoSG379u1D9erV1Q6DJGY0GpGXl6d2GGSn3r174+DBg4iPjy/9io6OxsMPP4z4+Hi4u7sLehy+vvWvS5cuOH78uMltJ06cQO3atVWKiKTyzTffICwszKSIllB8bTsXf39/VK9eHdeuXcOaNWtw9913qx0SqYwtw3RuypQpGDlyJKKjoxETE4N58+YhMTEREyZMUDs0ssP169dx6tSp0v+fPXsW8fHxCA4ORq1atTBt2jRcuHChdO/f7NmzERUVhWbNmpUWb/n111/x66+/qvUjkARefvll9O/fH5GRkcjKysKPP/6IDRs2YPXq1WqHRnYKCAhA8+bNTW7z9/dHSEhI6e18fbuGyZMno3Pnznj33Xfx4IMPYteuXZg3bx7mzZundmjkgOLiYnzzzTd45JFH4OFhennN17brWLNmDYxGIxo1aoRTp07hhRdeQKNGjfDYY4+pHRqpjINunRs6dCiuXLmCGTNmIDk5Gc2bN8eqVas4Y65TcXFx6NmzZ+n/p0yZAgB45JFHsGjRIiQnJ5ukIObn5+P555/HhQsX4Ovri2bNmuGvv/7CgAEDFI+dpHPp0iWMHDkSycnJCAoKQsuWLbF69WrceeedaodGMuLr2zW0b98eK1aswLRp0zBjxgzUqVMHs2fPxsMPP6x2aOSAdevWITExEaNHj67wPb62XUdGRgamTZuG8+fPIzg4GPfddx/eeecdeHp6qh0aqYyF1IiIiIiIiIhkwj3dRERERERERDLhoJuIiIiIiIhIJhx0ExEREREREcmEg24iIiIiIiIimXDQTURERERERCQTDrqJiIiIiIiIZMJBNxEREREREZFMOOgmIiIiIiIikgkH3URERE5u+vTpaN26tWrnf+211zBu3DhBxz7//POYOHGizBEREREpx2A0Go1qB0FERET2MRgMVr//yCOP4PPPP0deXh5CQkIUiuq2S5cuoUGDBjhw4ACioqJsHp+amop69erhwIEDqFOnjvwBEhERyYyDbiIiIh1LSUkp/feyZcvw+uuv4/jx46W3+fr6IigoSI3QAADvvvsuNm7ciDVr1gi+z3333Yf69evjf//7n4yRERERKYPp5URERDpWrVq10q+goCAYDIYKt5VPL3/00UcxZMgQvPvuuwgPD0flypXx5ptvorCwEC+88AKCg4NRs2ZNLFy40ORcFy5cwNChQ1GlShWEhITg7rvvRkJCgtX4fvzxRwwePNjktl9++QUtWrSAr68vQkJC0KdPH2RnZ5d+f/DgwVi6dKnDvxsiIiIt4KCbiIjIBf3333+4ePEiNm3ahI8++gjTp0/HoEGDUKVKFezcuRMTJkzAhAkTkJSUBADIyclBz549UalSJWzatAlbtmxBpUqV0K9fP+Tn55s9x7Vr13Do0CFER0eX3pacnIxhw4Zh9OjROHr0KDZs2IB7770XZRPvOnTogKSkJJw7d07eXwIREZECOOgmIiJyQcHBwfj000/RqFEjjB49Go0aNUJOTg5efvllNGjQANOmTYOXlxe2bt0K4OaKtZubG77++mu0aNECTZo0wTfffIPExERs2LDB7DnOnTsHo9GIiIiI0tuSk5NRWFiIe++9F1FRUWjRogWefPJJVKpUqfSYGjVqAIDNVXQiIiI98FA7ACIiIlJes2bN4OZ2e+49PDwczZs3L/2/u7s7QkJCkJqaCgDYs2cPTp06hYCAAJPHyc3NxenTp82e48aNGwAAHx+f0ttatWqF3r17o0WLFujbty9iY2Nx//33o0qVKqXH+Pr6Ari5uk5ERKR3HHQTERG5IE9PT5P/GwwGs7cVFxcDAIqLi9GuXTt8//33FR6ratWqZs8RGhoK4Gaaeckx7u7uWLt2LbZt24Z//vkHn332GV555RXs3LmztFr51atXrT4uERGRnjC9nIiIiGxq27YtTp48ibCwMNSvX9/ky1J19Hr16iEwMBBHjhwxud1gMKBLly548803sW/fPnh5eWHFihWl3z906BA8PT3RrFkzWX8mIiIiJXDQTURERDY9/PDDCA0Nxd13343Nmzfj7Nmz2LhxI5599lmcP3/e7H3c3NzQp08fbNmypfS2nTt34t1330VcXBwSExOxfPlyXL58GU2aNCk9ZvPmzejatWtpmjkREZGecdBNRERENvn5+WHTpk2oVasW7r33XjRp0gSjR4/GjRs3EBgYaPF+48aNw48//liaph4YGIhNmzZhwIABaNiwIV599VV8+OGH6N+/f+l9li5dirFjx8r+MxERESnBYCzbo4OIiIhIQkajEZ06dcKkSZMwbNgwm8f/9ddfeOGFF3DgwAF4eLD0DBER6R9XuomIiEg2BoMB8+bNQ2FhoaDjs7Oz8c0333DATUREToMr3UREREREREQy4Uo3ERERERERkUw46CYiIiIiIiKSCQfdRERERPT/9utYAAAAAGCQv/Uo9pVFAEykGwAAACbSDQAAABPpBgAAgIl0AwAAwES6AQAAYCLdAAAAMJFuAAAAmAS2LCiVFvmh8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = r\"dementia\\Abe Burrows\\AbeBurrows_5.wav\"\n",
    "\n",
    "# Force use of audioread by skipping soundfile (done implicitly if soundfile fails)\n",
    "y, sr = librosa.load(file_path, sr=None, mono=True, duration=10.0)\n",
    "\n",
    "print(f\"Audio loaded successfully: {y.shape}, Sample rate: {sr}\")\n",
    "\n",
    "# Plot waveform\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title(\"Waveform\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # --- 1. Mel-Spectrogram ---\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # --- 2. Acoustic Features ---\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "        mel = np.mean(log_mel_spectrogram.T, axis=0)\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr).T, axis=0)\n",
    "\n",
    "        # Combine acoustic features into one vector\n",
    "        acoustic_features = np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
    "\n",
    "        return log_mel_spectrogram, acoustic_features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a34410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel-Spectrogram shape: (128, 6118)\n",
      "Acoustic feature vector shape: (193,)\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "spec, acoustic = extract_features(r\"dementia\\Abe Burrows\\AbeBurrows_5.wav\")\n",
    "\n",
    "print(\"Mel-Spectrogram shape:\", spec.shape)\n",
    "print(\"Acoustic feature vector shape:\", acoustic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f32ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Abe Burrows\\AbeBurrows_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Aileen Hernandez\\aileenhernandez_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Aileen Hernandez\\aileenhernandez_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Aileen Hernandez\\aileenhernandez_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Alan Ramsey\\alanramsey_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Allan Burns\\AllanBurns_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Andrew Sachs\\andrewsachs_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Andrew Sachs\\andrewsachs_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Annette Michelson\\annettemichelson_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Antony Flew\\antonyflew_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Antony Flew\\antonyflew_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Antony Flew\\antonyflew_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\B B King\\bbking_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\B B King\\bbking_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\B B King\\bbking_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Barry Cohen\\BarryCohen_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ben Bradlee\\BenBradlee_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ben Bradlee\\BenBradlee_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Bill Buckner\\BillBuckner_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Bill Buckner\\BillBuckner_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Bill Buckner\\BillBuckner_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Bobby Womack\\BobbyWomack_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Casey Kasem\\CaseyKasem_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Casey Kasem\\CaseyKasem_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Charles Bronson\\CharlesBronson_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Charles Bronson\\CharlesBronson_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Charles K Kao\\CharlesKKao_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Charmian Carr\\CharmianCarr_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Charmian Carr\\CharmianCarr_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Dan Ingram\\daningram_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\David Milch\\DavidMilch_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\David Milch\\DavidMilch_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\David Prowse\\DavidProwse_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\David Prowse\\DavidProwse_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\David Prowse\\DavidProwse_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Dennis Moore\\DennisMoore_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Don Lane\\DonLane_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Donald Sterling\\DonaldSterling_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Emile Griffith\\emilegriffith_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ernie Sigley\\ErnieSigley_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Estelle Getty\\EstelleGetty_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Evelyn Keyes\\EvelynKeyes_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Evelyn Keyes\\EvelynKeyes_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Gale Sayers\\galesayers_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Gale Sayers\\galesayers_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Gale Sayers\\galesayers_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\George Klein\\georgeklein_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\George Klein\\georgeklein_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\George Klein\\georgeklein_5_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\George Robb\\georgerobb_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Greg Fingers Taylor\\GregFingersTaylor_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ian Holm\\IanHolm_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ian McCaskill\\ianmccaskill_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Iris Murdoch\\IrisMurdoch_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Iris Murdoch\\IrisMurdoch_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jack Hanna\\JackHanna_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jack Hanna\\JackHanna_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jack Webster\\JackWebster_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jack Webster\\JackWebster_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\James Stewart\\JamesStewart_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jeanne Little\\JeanneLittle_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jesse Helms\\jessehelms_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jesse Helms\\jessehelms_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jesse Helms\\jessehelms_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jessejackson\\Jessejackson_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jim McLean\\jimmclean_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jim Neidhart\\JimNeidhart_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jim Neidhart\\JimNeidhart_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jim Neidhart\\JimNeidhart_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jimmy Calderwood\\JimmyCalderwood_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jimmy Fratianno\\JimmyFratianno_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Joe Conley\\JoeConley_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\John Mackey\\johnmackey_15_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\John Mackey\\johnmackey_15_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Jonathan Miller\\JonathanMiller_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Leon Redbone\\leonredbone_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Lerone Bennett Jr\\LeroneBennettJr_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Maureen Forrester\\maureenforrester_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Maurice Hinchey\\mauricehinchey_0_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Maurice Hinchey\\mauricehinchey_0_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Maurice Hinchey\\mauricehinchey_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Omar Sharif\\OmarSharif_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Omar Sharif\\OmarSharif_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Otis Chandler\\OtisChandler_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Pat Pariseau\\patpariseau_10_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Pat Pariseau\\patpariseau_10_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Paul Hornung\\paulhornung_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Paul Hornung\\paulhornung_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Pauline Phillips\\PaulinePhillips_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Peter Falk\\PeterFalk_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Peter Falk\\PeterFalk_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Peter Max\\PeterMax_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Peter Max\\PeterMax_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Peter Reveen\\peterreveen_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ralph Klein\\ralphklein_5_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ralph Klein\\ralphklein_5_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ray Dolby\\RayDolby_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ray Dolby\\RayDolby_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ray Galton\\RayGalton_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Richard Gwyn\\RichardGwyn_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Richard Gwyn\\RichardGwyn_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Robert Anderson\\RobertAnderson_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Robin Williams\\RobinWilliams_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ronald Reagan\\RonaldReagan_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ronald Reagan\\RonaldReagan_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ronan O_Rahilly\\ronano_rahilly_15_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ronan O_Rahilly\\ronano_rahilly_15_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ross Mac Donald\\RossMacDonald_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Sparky Anderson\\SparkyAnderson_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Stan Bowles\\StanBowles_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Stella Stevens\\StellaStevens_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Steve Lawrence\\SteveLawrence_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ted Turner\\TedTurner_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Ted Turner\\TedTurner_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Teresa Gorman\\TeresaGorman_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Terry Jones\\terryjones_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Terry Pratchett\\TerryPratchett_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Terry Pratchett\\TerryPratchett_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Thomas Dorsey\\thomasdorsey_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tim Conway\\TimConway_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tim Conway\\TimConway_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tony Bennett\\TonyBennett_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tony Bennett\\TonyBennett_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tony Parkes\\TonyParkes_10.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Tony Parkes\\TonyParkes_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Trevor Peacock\\TrevorPeacock_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Unita Blackwell\\UnitaBlackwell_15.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Vampiro\\Vampiro_0.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Vampiro\\Vampiro_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Viv Nicholson\\vivnicholson_5.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\dementia\\Woody Durham\\woodydurham_0_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Barry Levinson\\BarryLevinson_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Barry Levinson\\BarryLevinson_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Barry Levinson\\BarryLevinson_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Bernie Sanders\\BernieSanders_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Bill Wyman\\BillWyman_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Bill Wyman\\BillWyman_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Bill Wyman\\BillWyman_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Christopher Plummer\\christopher plummer_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Dionne Warwick\\DionneWarwick_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Dionne Warwick\\DionneWarwick_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Dominic Chianese\\DominicChianese_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\George H W Bush\\GeorgeHWBush_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Harry Belafonte\\HarryBelafonte_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Harry Belafonte\\HarryBelafonte_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Harry Belafonte\\HarryBelafonte_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\James Brolin\\JamesBrolin_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\James Brolin\\JamesBrolin_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\James Caan\\JamesCaan_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\James Caan\\JamesCaan_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\James Earl Jones\\james earl jones_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Jerry Lewis\\JerryLewis1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Jerry Lewis\\JerryLewis2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Jerry Lewis\\JerryLewis3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Jimmy Carter\\Jimmy carter_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Joe Pesci\\JoePesci_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Joe Pesci\\JoePesci_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Joe Pesci\\JoePesci_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Judi Dench\\Judi Dench_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Judi Dench\\Judi Dench_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Kenny Rogers\\KennyRogers_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Kenny Rogers\\KennyRogers_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Kirk Douglas\\Kirk Douglas_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Kirk Douglas\\Kirk Douglas_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Kirk Douglas\\Kirk Douglas_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Line Renaud\\LineRenaud_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Line Renaud\\LineRenaud_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Martin Landau\\MartinLandau_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Martin Landau\\MartinLandau_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Max von Sydow\\MaxvonSydow_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Mel brooks\\Mel brooks_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Mel brooks\\Mel brooks_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Mel brooks\\Mel brooks_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Michael Dukakis\\MichaelDukakis_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Michael Dukakis\\MichaelDukakis_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Michael Gambon\\MichaelGambon_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Michael Gambon\\MichaelGambon_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Mireille Darc\\MireilleDarc_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Nick Nolte\\NickNolte_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Nick Nolte\\NickNolte_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Nick Nolte\\NickNolte_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Patrick Stewart\\Patrick Stewart_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Patrick Stewart\\Patrick Stewart_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Patrick Stewart\\Patrick Stewart_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Paul Sorvino\\PaulSorvino_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Paul Sorvino\\PaulSorvino_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Paul Verhoeven\\PaulVerhoeven_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Paul Verhoeven\\PaulVerhoeven_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Peter Fonda\\PeterFonda_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Peter Fonda\\PeterFonda_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Philip Glass\\PhilipGlass_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Philip Glass\\PhilipGlass_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Philip Glass\\PhilipGlass_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Prince Philip\\Prince Philip_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Prince Philip\\Prince Philip_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Prince Philip\\Prince Philip_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Ralph Lauren\\RalphLauren_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Raquel Welch\\RaquelWelch_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Raquel Welch\\RaquelWelch_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Raquel Welch\\RaquelWelch_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Richard Donner\\RichardDonner_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Richard Donner\\RichardDonner_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Robert De Niro\\RobertDeNiro_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Robert De Niro\\RobertDeNiro_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Robert Vaughn\\RobertVaughn_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Robert Vaughn\\RobertVaughn_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Roger Waters\\RogerWaters_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Roger Waters\\RogerWaters_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Rupert Murdoch\\RupertMurdoch_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Rupert Murdoch\\RupertMurdoch_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Rupert Murdoch\\RupertMurdoch_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Stan Lee\\Stan Lee_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Stan Lee\\Stan Lee_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Stan Lee\\Stan Lee_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Terry Riley\\TerryRiley_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Terry Riley\\TerryRiley_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Warren Buffett\\Warren Buffett_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Warren Buffett\\Warren Buffett_2.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Warren Buffett\\WarrenBuffett_3.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\William Shatner\\WilliamShatner_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Yoko Ono\\YokoOno_1.wav\n",
      "Processing: d:\\projects\\Big Projects\\AD detection\\nodementia\\Yoko Ono\\YokoOno_3.wav\n",
      "CNN input shape: (222, 128, 862)\n",
      "MLP input shape: (222, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "cnn_data = []\n",
    "cnn_labels = []\n",
    "\n",
    "mlp_data = []\n",
    "mlp_labels = []\n",
    "\n",
    "# No need for full path since you're already in the correct directory\n",
    "categories = {\n",
    "    \"dementia\": 1,\n",
    "    \"nodementia\": 0\n",
    "}\n",
    "\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=22050)\n",
    "        # Mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "\n",
    "        # Statistical features (mean, std) for MLP\n",
    "        mean = np.mean(log_mel_spec, axis=1)\n",
    "        std = np.std(log_mel_spec, axis=1)\n",
    "        features = np.concatenate((mean, std))\n",
    "\n",
    "        return log_mel_spec, features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to process:\", file_path)\n",
    "        print(\"Reason:\", e)\n",
    "        return None, None\n",
    "\n",
    "for category in categories:\n",
    "    label = categories[category]\n",
    "    category_path = os.path.join(os.getcwd(), category)  # Use current directory\n",
    "\n",
    "    for speaker in os.listdir(category_path):\n",
    "        speaker_path = os.path.join(category_path, speaker)\n",
    "\n",
    "        if os.path.isdir(speaker_path):\n",
    "            for file in os.listdir(speaker_path):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(speaker_path, file)\n",
    "                    print(\"Processing:\", file_path)\n",
    "\n",
    "                    spec, features = extract_features(file_path)\n",
    "\n",
    "                    if spec is not None and features is not None:\n",
    "                        padded_spec = librosa.util.fix_length(spec, size=862, axis=1)\n",
    "                        cnn_data.append(padded_spec)\n",
    "                        cnn_labels.append(label)\n",
    "\n",
    "                        mlp_data.append(features)\n",
    "                        mlp_labels.append(label)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_cnn = np.array(cnn_data)\n",
    "y_cnn = np.array(cnn_labels)\n",
    "\n",
    "X_mlp = np.array(mlp_data)\n",
    "y_mlp = np.array(mlp_labels)\n",
    "\n",
    "print(\"CNN input shape:\", X_cnn.shape)\n",
    "print(\"MLP input shape:\", X_mlp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac18acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\projects\\Big Projects\\AD detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ed1059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For CNN, add channel dimension (needed for Conv2D)\n",
    "X_cnn = X_cnn[..., np.newaxis]  # Shape: (222, 128, 862, 1)\n",
    "\n",
    "X_cnn_train, X_cnn_test, y_cnn_train, y_cnn_test = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42)\n",
    "X_mlp_train, X_mlp_test, y_mlp_train, y_mlp_test = train_test_split(X_mlp, y_mlp, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77de0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\acer\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/376.0 MB 1.7 MB/s eta 0:03:45\n",
      "   ---------------------------------------- 1.0/376.0 MB 2.1 MB/s eta 0:02:59\n",
      "   ---------------------------------------- 1.6/376.0 MB 2.3 MB/s eta 0:02:46\n",
      "   ---------------------------------------- 2.1/376.0 MB 2.1 MB/s eta 0:02:56\n",
      "   ---------------------------------------- 2.4/376.0 MB 2.2 MB/s eta 0:02:53\n",
      "   ---------------------------------------- 2.9/376.0 MB 2.1 MB/s eta 0:02:58\n",
      "   ---------------------------------------- 2.9/376.0 MB 2.1 MB/s eta 0:02:58\n",
      "   ---------------------------------------- 3.1/376.0 MB 1.9 MB/s eta 0:03:14\n",
      "   ---------------------------------------- 3.4/376.0 MB 1.8 MB/s eta 0:03:28\n",
      "   ---------------------------------------- 3.7/376.0 MB 1.7 MB/s eta 0:03:41\n",
      "   ---------------------------------------- 3.9/376.0 MB 1.6 MB/s eta 0:03:52\n",
      "   ---------------------------------------- 4.2/376.0 MB 1.6 MB/s eta 0:03:57\n",
      "   ---------------------------------------- 4.5/376.0 MB 1.5 MB/s eta 0:04:03\n",
      "    --------------------------------------- 4.7/376.0 MB 1.5 MB/s eta 0:04:04\n",
      "    --------------------------------------- 5.0/376.0 MB 1.5 MB/s eta 0:04:04\n",
      "    --------------------------------------- 5.2/376.0 MB 1.5 MB/s eta 0:04:01\n",
      "    --------------------------------------- 5.5/376.0 MB 1.5 MB/s eta 0:04:05\n",
      "    --------------------------------------- 5.8/376.0 MB 1.5 MB/s eta 0:04:07\n",
      "    --------------------------------------- 6.3/376.0 MB 1.5 MB/s eta 0:04:05\n",
      "    --------------------------------------- 6.8/376.0 MB 1.6 MB/s eta 0:03:58\n",
      "    --------------------------------------- 7.1/376.0 MB 1.6 MB/s eta 0:03:57\n",
      "    --------------------------------------- 7.3/376.0 MB 1.6 MB/s eta 0:03:56\n",
      "    --------------------------------------- 7.9/376.0 MB 1.6 MB/s eta 0:03:52\n",
      "    --------------------------------------- 8.4/376.0 MB 1.6 MB/s eta 0:03:47\n",
      "    --------------------------------------- 9.2/376.0 MB 1.7 MB/s eta 0:03:38\n",
      "   - -------------------------------------- 9.7/376.0 MB 1.7 MB/s eta 0:03:32\n",
      "   - -------------------------------------- 10.2/376.0 MB 1.8 MB/s eta 0:03:26\n",
      "   - -------------------------------------- 11.0/376.0 MB 1.8 MB/s eta 0:03:20\n",
      "   - -------------------------------------- 11.5/376.0 MB 1.9 MB/s eta 0:03:16\n",
      "   - -------------------------------------- 12.3/376.0 MB 1.9 MB/s eta 0:03:11\n",
      "   - -------------------------------------- 12.8/376.0 MB 1.9 MB/s eta 0:03:09\n",
      "   - -------------------------------------- 13.4/376.0 MB 2.0 MB/s eta 0:03:06\n",
      "   - -------------------------------------- 14.2/376.0 MB 2.0 MB/s eta 0:03:02\n",
      "   - -------------------------------------- 14.9/376.0 MB 2.1 MB/s eta 0:02:56\n",
      "   - -------------------------------------- 16.0/376.0 MB 2.1 MB/s eta 0:02:50\n",
      "   - -------------------------------------- 16.8/376.0 MB 2.2 MB/s eta 0:02:46\n",
      "   - -------------------------------------- 17.3/376.0 MB 2.2 MB/s eta 0:02:44\n",
      "   - -------------------------------------- 18.1/376.0 MB 2.2 MB/s eta 0:02:41\n",
      "   -- ------------------------------------- 18.9/376.0 MB 2.3 MB/s eta 0:02:39\n",
      "   -- ------------------------------------- 19.4/376.0 MB 2.3 MB/s eta 0:02:37\n",
      "   -- ------------------------------------- 20.2/376.0 MB 2.3 MB/s eta 0:02:34\n",
      "   -- ------------------------------------- 21.0/376.0 MB 2.4 MB/s eta 0:02:31\n",
      "   -- ------------------------------------- 21.8/376.0 MB 2.4 MB/s eta 0:02:29\n",
      "   -- ------------------------------------- 22.5/376.0 MB 2.4 MB/s eta 0:02:27\n",
      "   -- ------------------------------------- 23.6/376.0 MB 2.5 MB/s eta 0:02:24\n",
      "   -- ------------------------------------- 24.4/376.0 MB 2.5 MB/s eta 0:02:22\n",
      "   -- ------------------------------------- 25.2/376.0 MB 2.5 MB/s eta 0:02:20\n",
      "   -- ------------------------------------- 26.2/376.0 MB 2.6 MB/s eta 0:02:17\n",
      "   -- ------------------------------------- 27.3/376.0 MB 2.6 MB/s eta 0:02:14\n",
      "   --- ------------------------------------ 28.3/376.0 MB 2.7 MB/s eta 0:02:11\n",
      "   --- ------------------------------------ 29.1/376.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.6/376.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 30.4/376.0 MB 2.7 MB/s eta 0:02:09\n",
      "   --- ------------------------------------ 30.9/376.0 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 31.5/376.0 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 32.0/376.0 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 32.2/376.0 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 32.8/376.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 33.0/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 33.6/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 34.1/376.0 MB 2.6 MB/s eta 0:02:11\n",
      "   --- ------------------------------------ 34.6/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 35.1/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 35.7/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 36.2/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 36.7/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 37.2/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 37.5/376.0 MB 2.6 MB/s eta 0:02:10\n",
      "   ---- ----------------------------------- 38.0/376.0 MB 2.6 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 38.3/376.0 MB 2.6 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 38.3/376.0 MB 2.6 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 38.8/376.0 MB 2.5 MB/s eta 0:02:14\n",
      "   ---- ----------------------------------- 39.1/376.0 MB 2.5 MB/s eta 0:02:14\n",
      "   ---- ----------------------------------- 39.3/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 39.8/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 40.1/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 40.6/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 41.2/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 41.7/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 42.2/376.0 MB 2.5 MB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 43.0/376.0 MB 2.5 MB/s eta 0:02:14\n",
      "   ---- ----------------------------------- 43.8/376.0 MB 2.5 MB/s eta 0:02:13\n",
      "   ---- ----------------------------------- 44.3/376.0 MB 2.5 MB/s eta 0:02:13\n",
      "   ---- ----------------------------------- 45.1/376.0 MB 2.5 MB/s eta 0:02:12\n",
      "   ---- ----------------------------------- 45.6/376.0 MB 2.5 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 46.4/376.0 MB 2.5 MB/s eta 0:02:10\n",
      "   ----- ---------------------------------- 47.2/376.0 MB 2.5 MB/s eta 0:02:10\n",
      "   ----- ---------------------------------- 48.0/376.0 MB 2.6 MB/s eta 0:02:09\n",
      "   ----- ---------------------------------- 48.8/376.0 MB 2.6 MB/s eta 0:02:08\n",
      "   ----- ---------------------------------- 49.3/376.0 MB 2.6 MB/s eta 0:02:08\n",
      "   ----- ---------------------------------- 50.1/376.0 MB 2.6 MB/s eta 0:02:07\n",
      "   ----- ---------------------------------- 50.3/376.0 MB 2.6 MB/s eta 0:02:07\n",
      "   ----- ---------------------------------- 51.1/376.0 MB 2.6 MB/s eta 0:02:06\n",
      "   ----- ---------------------------------- 51.9/376.0 MB 2.6 MB/s eta 0:02:06\n",
      "   ----- ---------------------------------- 52.7/376.0 MB 2.6 MB/s eta 0:02:05\n",
      "   ----- ---------------------------------- 53.5/376.0 MB 2.6 MB/s eta 0:02:04\n",
      "   ----- ---------------------------------- 54.3/376.0 MB 2.6 MB/s eta 0:02:03\n",
      "   ----- ---------------------------------- 55.1/376.0 MB 2.6 MB/s eta 0:02:02\n",
      "   ----- ---------------------------------- 56.1/376.0 MB 2.7 MB/s eta 0:02:01\n",
      "   ------ --------------------------------- 56.9/376.0 MB 2.7 MB/s eta 0:02:00\n",
      "   ------ --------------------------------- 57.9/376.0 MB 2.7 MB/s eta 0:01:59\n",
      "   ------ --------------------------------- 59.0/376.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------ --------------------------------- 60.0/376.0 MB 2.7 MB/s eta 0:01:56\n",
      "   ------ --------------------------------- 60.8/376.0 MB 2.7 MB/s eta 0:01:55\n",
      "   ------ --------------------------------- 62.1/376.0 MB 2.8 MB/s eta 0:01:54\n",
      "   ------ --------------------------------- 63.2/376.0 MB 2.8 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 64.5/376.0 MB 2.8 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 65.5/376.0 MB 2.8 MB/s eta 0:01:49\n",
      "   ------- -------------------------------- 66.8/376.0 MB 2.9 MB/s eta 0:01:48\n",
      "   ------- -------------------------------- 67.9/376.0 MB 2.9 MB/s eta 0:01:47\n",
      "   ------- -------------------------------- 69.2/376.0 MB 2.9 MB/s eta 0:01:45\n",
      "   ------- -------------------------------- 70.3/376.0 MB 2.9 MB/s eta 0:01:44\n",
      "   ------- -------------------------------- 71.6/376.0 MB 3.0 MB/s eta 0:01:43\n",
      "   ------- -------------------------------- 72.6/376.0 MB 3.0 MB/s eta 0:01:42\n",
      "   ------- -------------------------------- 74.2/376.0 MB 3.0 MB/s eta 0:01:40\n",
      "   -------- ------------------------------- 75.5/376.0 MB 3.1 MB/s eta 0:01:39\n",
      "   -------- ------------------------------- 76.8/376.0 MB 3.1 MB/s eta 0:01:38\n",
      "   -------- ------------------------------- 78.4/376.0 MB 3.1 MB/s eta 0:01:36\n",
      "   -------- ------------------------------- 79.7/376.0 MB 3.1 MB/s eta 0:01:35\n",
      "   -------- ------------------------------- 81.3/376.0 MB 3.2 MB/s eta 0:01:33\n",
      "   -------- ------------------------------- 82.3/376.0 MB 3.2 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 83.6/376.0 MB 3.2 MB/s eta 0:01:31\n",
      "   --------- ------------------------------ 84.7/376.0 MB 3.2 MB/s eta 0:01:30\n",
      "   --------- ------------------------------ 85.5/376.0 MB 3.2 MB/s eta 0:01:30\n",
      "   --------- ------------------------------ 86.8/376.0 MB 3.3 MB/s eta 0:01:29\n",
      "   --------- ------------------------------ 88.3/376.0 MB 3.3 MB/s eta 0:01:28\n",
      "   --------- ------------------------------ 89.7/376.0 MB 3.3 MB/s eta 0:01:27\n",
      "   --------- ------------------------------ 91.0/376.0 MB 3.3 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 92.5/376.0 MB 3.4 MB/s eta 0:01:25\n",
      "   --------- ------------------------------ 93.8/376.0 MB 3.4 MB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 95.2/376.0 MB 3.4 MB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 96.5/376.0 MB 3.4 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 97.8/376.0 MB 3.5 MB/s eta 0:01:21\n",
      "   ---------- ----------------------------- 99.1/376.0 MB 3.5 MB/s eta 0:01:20\n",
      "   ---------- ----------------------------- 100.7/376.0 MB 3.5 MB/s eta 0:01:19\n",
      "   ---------- ----------------------------- 101.7/376.0 MB 3.5 MB/s eta 0:01:19\n",
      "   ---------- ----------------------------- 102.8/376.0 MB 3.5 MB/s eta 0:01:18\n",
      "   ----------- ---------------------------- 103.8/376.0 MB 3.5 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 105.1/376.0 MB 3.6 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 106.4/376.0 MB 3.6 MB/s eta 0:01:16\n",
      "   ----------- ---------------------------- 107.5/376.0 MB 3.6 MB/s eta 0:01:15\n",
      "   ----------- ---------------------------- 108.8/376.0 MB 3.6 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 110.4/376.0 MB 3.6 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 111.4/376.0 MB 3.7 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 112.7/376.0 MB 3.7 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 113.8/376.0 MB 3.7 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 115.1/376.0 MB 3.7 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 116.7/376.0 MB 3.8 MB/s eta 0:01:09\n",
      "   ------------ --------------------------- 117.7/376.0 MB 3.8 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 118.8/376.0 MB 3.9 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 119.8/376.0 MB 3.9 MB/s eta 0:01:06\n",
      "   ------------ --------------------------- 120.8/376.0 MB 3.9 MB/s eta 0:01:06\n",
      "   ------------ --------------------------- 122.2/376.0 MB 4.0 MB/s eta 0:01:05\n",
      "   ------------- -------------------------- 122.9/376.0 MB 4.0 MB/s eta 0:01:04\n",
      "   ------------- -------------------------- 124.0/376.0 MB 4.0 MB/s eta 0:01:04\n",
      "   ------------- -------------------------- 125.3/376.0 MB 4.0 MB/s eta 0:01:03\n",
      "   ------------- -------------------------- 126.6/376.0 MB 4.0 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 127.4/376.0 MB 4.1 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 127.9/376.0 MB 4.1 MB/s eta 0:01:01\n",
      "   ------------- -------------------------- 129.0/376.0 MB 4.1 MB/s eta 0:01:01\n",
      "   ------------- -------------------------- 130.3/376.0 MB 4.1 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 131.3/376.0 MB 4.1 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 131.9/376.0 MB 4.2 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 132.9/376.0 MB 4.2 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 134.0/376.0 MB 4.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 135.3/376.0 MB 4.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 136.3/376.0 MB 4.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 137.6/376.0 MB 4.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 138.7/376.0 MB 4.3 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 140.0/376.0 MB 4.3 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 141.3/376.0 MB 4.3 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 142.6/376.0 MB 4.3 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 144.2/376.0 MB 4.4 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 145.2/376.0 MB 4.4 MB/s eta 0:00:53\n",
      "   --------------- ------------------------ 146.5/376.0 MB 4.4 MB/s eta 0:00:53\n",
      "   --------------- ------------------------ 147.6/376.0 MB 4.4 MB/s eta 0:00:52\n",
      "   --------------- ------------------------ 148.6/376.0 MB 4.4 MB/s eta 0:00:52\n",
      "   --------------- ------------------------ 149.9/376.0 MB 4.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 151.3/376.0 MB 4.4 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 152.8/376.0 MB 4.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 154.1/376.0 MB 4.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 154.9/376.0 MB 4.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 156.2/376.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 157.3/376.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 158.3/376.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 159.4/376.0 MB 4.5 MB/s eta 0:00:48\n",
      "   ----------------- ---------------------- 160.7/376.0 MB 4.5 MB/s eta 0:00:48\n",
      "   ----------------- ---------------------- 161.7/376.0 MB 4.5 MB/s eta 0:00:48\n",
      "   ----------------- ---------------------- 162.5/376.0 MB 4.5 MB/s eta 0:00:48\n",
      "   ----------------- ---------------------- 163.6/376.0 MB 4.5 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 164.4/376.0 MB 4.5 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 165.2/376.0 MB 4.5 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 165.7/376.0 MB 4.5 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 166.7/376.0 MB 4.5 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 167.8/376.0 MB 4.6 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 168.8/376.0 MB 4.6 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 169.1/376.0 MB 4.6 MB/s eta 0:00:46\n",
      "   ------------------ --------------------- 169.3/376.0 MB 4.6 MB/s eta 0:00:46\n",
      "   ------------------ --------------------- 170.4/376.0 MB 4.6 MB/s eta 0:00:45\n",
      "   ------------------ --------------------- 171.2/376.0 MB 4.6 MB/s eta 0:00:45\n",
      "   ------------------ --------------------- 172.2/376.0 MB 4.6 MB/s eta 0:00:45\n",
      "   ------------------ --------------------- 172.8/376.0 MB 4.6 MB/s eta 0:00:44\n",
      "   ------------------ --------------------- 173.5/376.0 MB 4.6 MB/s eta 0:00:44\n",
      "   ------------------ --------------------- 174.6/376.0 MB 4.6 MB/s eta 0:00:44\n",
      "   ------------------ --------------------- 175.9/376.0 MB 4.7 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 177.2/376.0 MB 4.7 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 178.5/376.0 MB 4.7 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 179.6/376.0 MB 4.7 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 180.9/376.0 MB 4.8 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 181.9/376.0 MB 4.8 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 183.0/376.0 MB 4.8 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 184.0/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 185.1/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 185.9/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 186.1/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 186.4/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 187.4/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 188.0/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 188.5/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 188.7/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 189.8/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 190.8/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 191.9/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 192.4/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 192.9/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 194.0/376.0 MB 4.9 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 195.0/376.0 MB 5.0 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 196.3/376.0 MB 5.0 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 197.4/376.0 MB 5.0 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 198.4/376.0 MB 5.0 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 199.8/376.0 MB 5.0 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 201.1/376.0 MB 5.0 MB/s eta 0:00:35\n",
      "   --------------------- ------------------ 202.1/376.0 MB 5.1 MB/s eta 0:00:35\n",
      "   --------------------- ------------------ 203.2/376.0 MB 5.1 MB/s eta 0:00:35\n",
      "   --------------------- ------------------ 203.9/376.0 MB 5.1 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 205.3/376.0 MB 5.1 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 206.0/376.0 MB 5.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 206.8/376.0 MB 5.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 207.9/376.0 MB 5.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 208.9/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 210.0/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 210.5/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 211.3/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 212.3/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 213.4/376.0 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 214.7/376.0 MB 5.1 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 215.5/376.0 MB 5.1 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 216.3/376.0 MB 5.1 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 217.6/376.0 MB 5.1 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 218.9/376.0 MB 5.1 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 220.2/376.0 MB 5.1 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 221.5/376.0 MB 5.1 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 222.6/376.0 MB 5.1 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 223.9/376.0 MB 5.1 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 224.4/376.0 MB 5.1 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 225.2/376.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 226.5/376.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 227.5/376.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 228.6/376.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 230.2/376.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 231.7/376.0 MB 5.0 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 232.8/376.0 MB 5.0 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 233.8/376.0 MB 5.0 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 234.6/376.0 MB 5.0 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 235.9/376.0 MB 5.0 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 237.0/376.0 MB 5.0 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 237.8/376.0 MB 5.0 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 238.6/376.0 MB 5.0 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 239.3/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 240.1/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 240.9/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 242.0/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 243.0/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 243.8/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 244.8/376.0 MB 4.8 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 245.9/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 246.7/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 247.7/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 249.0/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 249.8/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 251.1/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 252.4/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 253.2/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 254.3/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 255.6/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 256.6/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 257.7/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 258.7/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 259.8/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 261.1/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 262.4/376.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 263.5/376.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 264.5/376.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 266.1/376.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 267.4/376.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 268.7/376.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 270.0/376.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 271.6/376.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 273.2/376.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 274.5/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 276.0/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 277.6/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 278.7/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 279.7/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 281.5/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 283.4/376.0 MB 5.0 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 285.0/376.0 MB 5.0 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 286.5/376.0 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 288.6/376.0 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 289.1/376.0 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 290.2/376.0 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 291.8/376.0 MB 5.0 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 293.9/376.0 MB 5.0 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 295.7/376.0 MB 5.0 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 297.3/376.0 MB 5.0 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 299.1/376.0 MB 5.1 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 301.2/376.0 MB 5.1 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 303.0/376.0 MB 5.1 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 305.1/376.0 MB 5.2 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 307.2/376.0 MB 5.2 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 309.3/376.0 MB 5.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 310.9/376.0 MB 5.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 312.7/376.0 MB 5.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 313.8/376.0 MB 5.2 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 315.4/376.0 MB 5.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 317.2/376.0 MB 5.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 319.3/376.0 MB 5.3 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 321.1/376.0 MB 5.3 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 323.0/376.0 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 324.8/376.0 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 326.9/376.0 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 328.7/376.0 MB 5.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 330.8/376.0 MB 5.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 332.9/376.0 MB 5.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 334.8/376.0 MB 5.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 336.6/376.0 MB 5.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 338.2/376.0 MB 5.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 339.7/376.0 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 341.0/376.0 MB 5.7 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 342.9/376.0 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 344.2/376.0 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 345.2/376.0 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 346.6/376.0 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 347.9/376.0 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.2/376.0 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.7/376.0 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 350.5/376.0 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 351.8/376.0 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 353.6/376.0 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.9/376.0 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 356.0/376.0 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 357.6/376.0 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 359.4/376.0 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.2/376.0 MB 5.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.1/376.0 MB 5.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 364.9/376.0 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 366.5/376.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.1/376.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.9/376.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  371.5/376.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.3/376.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.1/376.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 376.0/376.0 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.8/4.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/26.4 MB 9.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 8.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.5/26.4 MB 8.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.7/26.4 MB 8.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.2/26.4 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.6/26.4 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.4 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.3/26.4 MB 7.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.4 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.9/26.4 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.5 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow --timeout=1000 --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e92f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">430</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">428</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">214</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">410880</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">26,296,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m860\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m430\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m428\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m214\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m410880\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m26,296,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,315,265</span> (100.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,315,265\u001b[0m (100.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,315,265</span> (100.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,315,265\u001b[0m (100.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 862, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb7f1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,217</span> (161.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,217\u001b[0m (161.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,217</span> (161.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,217\u001b[0m (161.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(256,)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mlp_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2fffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 831ms/step - accuracy: 0.4888 - loss: 355.3591 - val_accuracy: 0.6667 - val_loss: 14.3541\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 725ms/step - accuracy: 0.5499 - loss: 16.3040 - val_accuracy: 0.3333 - val_loss: 1.2038\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 727ms/step - accuracy: 0.5468 - loss: 0.7050 - val_accuracy: 0.6667 - val_loss: 0.6618\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 734ms/step - accuracy: 0.5897 - loss: 0.6668 - val_accuracy: 0.6667 - val_loss: 0.6879\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 720ms/step - accuracy: 0.6630 - loss: 0.6659 - val_accuracy: 0.6111 - val_loss: 0.6881\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 731ms/step - accuracy: 0.7588 - loss: 0.6073 - val_accuracy: 0.6667 - val_loss: 0.6673\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 746ms/step - accuracy: 0.7820 - loss: 0.4899 - val_accuracy: 0.5556 - val_loss: 0.7205\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 764ms/step - accuracy: 0.7867 - loss: 0.4135 - val_accuracy: 0.5556 - val_loss: 0.7448\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 788ms/step - accuracy: 0.9492 - loss: 0.2605 - val_accuracy: 0.3889 - val_loss: 0.9362\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 707ms/step - accuracy: 0.9669 - loss: 0.1448 - val_accuracy: 0.5000 - val_loss: 1.0736\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 708ms/step - accuracy: 0.9746 - loss: 0.0940 - val_accuracy: 0.4444 - val_loss: 1.2705\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739ms/step - accuracy: 0.9616 - loss: 0.0960 - val_accuracy: 0.5556 - val_loss: 1.5136\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 788ms/step - accuracy: 0.9646 - loss: 0.0588 - val_accuracy: 0.3889 - val_loss: 1.3530\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 730ms/step - accuracy: 0.9860 - loss: 0.0527 - val_accuracy: 0.4444 - val_loss: 1.3612\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 708ms/step - accuracy: 0.9838 - loss: 0.0413 - val_accuracy: 0.4444 - val_loss: 1.9568\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 742ms/step - accuracy: 0.9523 - loss: 0.0603 - val_accuracy: 0.4444 - val_loss: 1.8257\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 753ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.5000 - val_loss: 1.9687\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 718ms/step - accuracy: 0.9935 - loss: 0.0178 - val_accuracy: 0.5000 - val_loss: 1.8464\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 715ms/step - accuracy: 0.9795 - loss: 0.0307 - val_accuracy: 0.4444 - val_loss: 1.9691\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 757ms/step - accuracy: 0.9846 - loss: 0.0352 - val_accuracy: 0.3333 - val_loss: 2.4002\n",
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5616 - loss: 12.3211 - val_accuracy: 0.3333 - val_loss: 4.9672\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5398 - loss: 5.1178 - val_accuracy: 0.6111 - val_loss: 1.1021\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4249 - loss: 3.4265 - val_accuracy: 0.6667 - val_loss: 1.9539\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5175 - loss: 3.2350 - val_accuracy: 0.3333 - val_loss: 1.2089\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5077 - loss: 2.2124 - val_accuracy: 0.7222 - val_loss: 0.5555\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4958 - loss: 1.9457 - val_accuracy: 0.6667 - val_loss: 1.5844\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5105 - loss: 1.8175 - val_accuracy: 0.3333 - val_loss: 1.6567\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4330 - loss: 1.4143 - val_accuracy: 0.3333 - val_loss: 0.8109\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4650 - loss: 1.3137 - val_accuracy: 0.6667 - val_loss: 0.7406\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5400 - loss: 1.2486 - val_accuracy: 0.3333 - val_loss: 0.9707\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4898 - loss: 1.0138 - val_accuracy: 0.6667 - val_loss: 0.9163\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4899 - loss: 0.9246 - val_accuracy: 0.7222 - val_loss: 0.6521\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5144 - loss: 0.9175 - val_accuracy: 0.7222 - val_loss: 0.6274\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5518 - loss: 0.7270 - val_accuracy: 0.3889 - val_loss: 0.7213\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5135 - loss: 0.8028 - val_accuracy: 0.6667 - val_loss: 0.6229\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5401 - loss: 0.7140 - val_accuracy: 0.6111 - val_loss: 0.7026\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5130 - loss: 0.8681 - val_accuracy: 0.7778 - val_loss: 0.5641\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.8121 - val_accuracy: 0.6667 - val_loss: 0.5822\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5820 - loss: 0.6943 - val_accuracy: 0.6667 - val_loss: 0.6302\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5208 - loss: 0.6960 - val_accuracy: 0.5000 - val_loss: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x264d53be3c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_cnn_train, y_cnn_train, epochs=20, batch_size=16, validation_split=0.1)\n",
    "mlp_model.fit(X_mlp_train, y_mlp_train, epochs=20, batch_size=16, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb247dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4674 - loss: 1.8941\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4970 - loss: 0.6622\n",
      "✅ CNN Test Accuracy: 46.67%\n",
      "✅ MLP Test Accuracy: 51.11%\n"
     ]
    }
   ],
   "source": [
    "cnn_eval = cnn_model.evaluate(X_cnn_test, y_cnn_test)\n",
    "mlp_eval = mlp_model.evaluate(X_mlp_test, y_mlp_test)\n",
    "\n",
    "print(f\"✅ CNN Test Accuracy: {cnn_eval[1]*100:.2f}%\")\n",
    "print(f\"✅ MLP Test Accuracy: {mlp_eval[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26e79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5298e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 131, 0: 91})\n",
      "Counter({1: 131, 0: 91})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_cnn))\n",
    "print(Counter(y_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d67788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_cnn),\n",
    "    y=y_cnn\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6494d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.9928 - loss: 0.0316 - val_accuracy: 0.3889 - val_loss: 2.4976\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 830ms/step - accuracy: 0.9563 - loss: 0.0619 - val_accuracy: 0.5000 - val_loss: 2.2117\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 765ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.2778 - val_loss: 2.6585\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 771ms/step - accuracy: 0.9783 - loss: 0.0348 - val_accuracy: 0.3333 - val_loss: 2.5579\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 720ms/step - accuracy: 0.9913 - loss: 0.0326 - val_accuracy: 0.3889 - val_loss: 2.4077\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 755ms/step - accuracy: 0.9982 - loss: 0.0227 - val_accuracy: 0.4444 - val_loss: 2.4743\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.4444 - val_loss: 2.8097\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 803ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.2222 - val_loss: 3.2289\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 800ms/step - accuracy: 0.9967 - loss: 0.0202 - val_accuracy: 0.3333 - val_loss: 2.8054\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 777ms/step - accuracy: 0.9819 - loss: 0.0295 - val_accuracy: 0.5556 - val_loss: 2.4723\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.5556 - val_loss: 2.6012\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 874ms/step - accuracy: 0.9928 - loss: 0.0215 - val_accuracy: 0.2222 - val_loss: 2.8714\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.2222 - val_loss: 2.8393\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 795ms/step - accuracy: 0.9907 - loss: 0.0374 - val_accuracy: 0.3333 - val_loss: 2.6472\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.3333 - val_loss: 2.8104\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.3333 - val_loss: 3.2145\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 782ms/step - accuracy: 0.9885 - loss: 0.0251 - val_accuracy: 0.3889 - val_loss: 3.0272\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 752ms/step - accuracy: 0.9828 - loss: 0.0207 - val_accuracy: 0.3889 - val_loss: 3.2193\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 764ms/step - accuracy: 0.9716 - loss: 0.0286 - val_accuracy: 0.4444 - val_loss: 3.3387\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739ms/step - accuracy: 0.9946 - loss: 0.0347 - val_accuracy: 0.4444 - val_loss: 3.3808\n",
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4750 - loss: 0.7478 - val_accuracy: 0.5000 - val_loss: 0.6903\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5562 - loss: 0.7204 - val_accuracy: 0.5556 - val_loss: 0.6698\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5292 - loss: 0.7212 - val_accuracy: 0.4444 - val_loss: 0.6802\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5481 - loss: 0.7043 - val_accuracy: 0.3333 - val_loss: 0.7545\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5298 - loss: 0.7156 - val_accuracy: 0.5556 - val_loss: 0.7213\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5376 - loss: 0.6981 - val_accuracy: 0.5000 - val_loss: 0.7121\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5898 - loss: 0.6828 - val_accuracy: 0.5000 - val_loss: 0.7032\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5377 - loss: 0.7424 - val_accuracy: 0.4444 - val_loss: 0.7131\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4835 - loss: 0.7381 - val_accuracy: 0.5556 - val_loss: 0.6718\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5444 - loss: 0.6862 - val_accuracy: 0.4444 - val_loss: 0.7158\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4946 - loss: 0.7032 - val_accuracy: 0.4444 - val_loss: 0.7656\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4961 - loss: 0.7139 - val_accuracy: 0.5556 - val_loss: 0.6643\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 0.7084 - val_accuracy: 0.5556 - val_loss: 0.6841\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4808 - loss: 0.6939 - val_accuracy: 0.3889 - val_loss: 0.7079\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4767 - loss: 0.6919 - val_accuracy: 0.3333 - val_loss: 0.7408\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5007 - loss: 0.6802 - val_accuracy: 0.6667 - val_loss: 0.6390\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6053 - loss: 0.6689 - val_accuracy: 0.6111 - val_loss: 0.6848\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4954 - loss: 0.7140 - val_accuracy: 0.3889 - val_loss: 0.7285\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4427 - loss: 0.6825 - val_accuracy: 0.7222 - val_loss: 0.6497\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5288 - loss: 0.6835 - val_accuracy: 0.6111 - val_loss: 0.6580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x264cfcb6bd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    X_cnn_train, y_cnn_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "mlp_model.fit(\n",
    "    X_mlp_train, y_mlp_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8acd5c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4273 - loss: 2.7672\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5623 - loss: 0.6705\n",
      "✅ CNN Test Accuracy: 42.22%\n",
      "✅ MLP Test Accuracy: 57.78%\n"
     ]
    }
   ],
   "source": [
    "cnn_eval = cnn_model.evaluate(X_cnn_test, y_cnn_test)\n",
    "mlp_eval = mlp_model.evaluate(X_mlp_test, y_mlp_test)\n",
    "\n",
    "print(f\"✅ CNN Test Accuracy: {cnn_eval[1]*100:.2f}%\")\n",
    "print(f\"✅ MLP Test Accuracy: {mlp_eval[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1425020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_mlp_balanced, y_mlp_balanced = sm.fit_resample(X_mlp, y_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952a809",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3499fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X_cnn_flat = X_cnn.reshape(X_cnn.shape[0], -1)  # flatten for oversampling\n",
    "ros = RandomOverSampler()\n",
    "X_cnn_resampled, y_cnn_resampled = ros.fit_resample(X_cnn_flat, y_cnn)\n",
    "\n",
    "# Reshape back to original CNN shape\n",
    "X_cnn_resampled = X_cnn_resampled.reshape(-1, 128, 862, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e915de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cnn_train, X_cnn_test, y_cnn_train, y_cnn_test = train_test_split(\n",
    "    X_cnn_resampled, y_cnn_resampled, test_size=0.2, random_state=42, stratify=y_cnn_resampled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea61ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 797ms/step - accuracy: 0.8703 - loss: 0.5505 - val_accuracy: 0.6667 - val_loss: 0.5563\n",
      "Epoch 2/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 691ms/step - accuracy: 0.9255 - loss: 0.3703 - val_accuracy: 0.7143 - val_loss: 0.5083\n",
      "Epoch 3/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 690ms/step - accuracy: 0.9272 - loss: 0.2227 - val_accuracy: 0.6667 - val_loss: 0.7293\n",
      "Epoch 4/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 700ms/step - accuracy: 0.9534 - loss: 0.1120 - val_accuracy: 0.7619 - val_loss: 0.7595\n",
      "Epoch 5/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789ms/step - accuracy: 0.9810 - loss: 0.0694 - val_accuracy: 0.6667 - val_loss: 0.8073\n",
      "Epoch 6/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 693ms/step - accuracy: 0.9800 - loss: 0.0473 - val_accuracy: 0.7143 - val_loss: 0.9163\n",
      "Epoch 7/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 755ms/step - accuracy: 0.9924 - loss: 0.0273 - val_accuracy: 0.6667 - val_loss: 1.1485\n",
      "Epoch 8/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 741ms/step - accuracy: 0.9777 - loss: 0.0473 - val_accuracy: 0.6667 - val_loss: 1.3572\n",
      "Epoch 9/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 706ms/step - accuracy: 0.9891 - loss: 0.0291 - val_accuracy: 0.6667 - val_loss: 1.1789\n",
      "Epoch 10/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 704ms/step - accuracy: 0.9908 - loss: 0.0584 - val_accuracy: 0.6667 - val_loss: 1.2271\n",
      "Epoch 11/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 731ms/step - accuracy: 0.9882 - loss: 0.0902 - val_accuracy: 0.7619 - val_loss: 0.9763\n",
      "Epoch 12/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 718ms/step - accuracy: 0.9947 - loss: 0.0373 - val_accuracy: 0.7143 - val_loss: 0.9655\n",
      "Epoch 13/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 727ms/step - accuracy: 0.9842 - loss: 0.0415 - val_accuracy: 0.7143 - val_loss: 1.0431\n",
      "Epoch 14/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 688ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.7143 - val_loss: 1.1377\n",
      "Epoch 15/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 706ms/step - accuracy: 0.9956 - loss: 0.0294 - val_accuracy: 0.7619 - val_loss: 1.1596\n",
      "Epoch 16/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 772ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.7143 - val_loss: 1.1505\n",
      "Epoch 17/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 775ms/step - accuracy: 0.9983 - loss: 0.0137 - val_accuracy: 0.7143 - val_loss: 1.3195\n",
      "Epoch 18/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 0.7619 - val_loss: 1.4755\n",
      "Epoch 19/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 788ms/step - accuracy: 0.9971 - loss: 0.0128 - val_accuracy: 0.7143 - val_loss: 1.4622\n",
      "Epoch 20/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 760ms/step - accuracy: 0.9971 - loss: 0.0247 - val_accuracy: 0.7619 - val_loss: 1.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x264d23910d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    X_cnn_train, y_cnn_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40904cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9644 - loss: 0.2313\n",
      "✅ CNN Test Accuracy After Balancing: 96.23%\n"
     ]
    }
   ],
   "source": [
    "cnn_eval = cnn_model.evaluate(X_cnn_test, y_cnn_test)\n",
    "print(f\"✅ CNN Test Accuracy After Balancing: {cnn_eval[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f7612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced y_cnn: Counter({1: 131, 0: 131})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Balanced y_cnn:\", Counter(y_cnn_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d372632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "cnn_model.save(\"final_cnn_alzheimer_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6afd6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 128, 862, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cnn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19a010d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddeviceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sounddevice-0.5.2-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: librosa in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acer\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Downloading sounddevice-0.5.2-py3-none-win_amd64.whl (363 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.2\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204d1456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "🧠 Predicted Class: Not Alzheimer\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"D:/projects/Big Projects/AD detection/final_cnn_alzheimer_model.h5\")\n",
    "\n",
    "def preprocess_audio(file_path, target_shape=(128, 862)):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    \n",
    "    # Generate mel spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Resize or pad to match training input\n",
    "    if mel_spec_db.shape[1] < target_shape[1]:\n",
    "        pad_width = target_shape[1] - mel_spec_db.shape[1]\n",
    "        mel_spec_db = np.pad(mel_spec_db, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db[:, :target_shape[1]]\n",
    "\n",
    "    mel_spec_db = mel_spec_db.reshape(target_shape[0], target_shape[1], 1)\n",
    "    mel_spec_db = mel_spec_db / 255.0  # Normalize if you did that during training\n",
    "    return np.expand_dims(mel_spec_db, axis=0)  # Add batch dimension\n",
    "\n",
    "# Upload audio file (manually upload for now)\n",
    "file_path = \"D:/projects/Big Projects/AD detection/test_audio2.wav\"  # Replace with your test audio\n",
    "\n",
    "# Preprocess and predict\n",
    "input_data = preprocess_audio(file_path)\n",
    "prediction = model.predict(input_data)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Result\n",
    "classes = ['Not Alzheimer', 'Alzheimer']  # Modify according to your labels\n",
    "print(f\"🧠 Predicted Class: {classes[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af11e5",
   "metadata": {},
   "source": [
    "## Multimodal Model: CNN (Audio) + LSTM (Transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d9c3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filepath     label  \\\n",
      "0  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia   \n",
      "1  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia   \n",
      "2  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia   \n",
      "3  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia   \n",
      "4  D:\\projects\\Big Projects\\AD detection\\dementia...  dementia   \n",
      "\n",
      "                                          transcript  \n",
      "0   He was worried when I became a performer. He ...  \n",
      "1   This is not going to sound like very ladylike...  \n",
      "2   I arrive at my first political science class....  \n",
      "3   We are more conscious in this state now about...  \n",
      "4   I have no real love for the two leaders. I th...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the updated CSV\n",
    "df = pd.read_csv(\"data_with_transcripts.csv\")  # replace with your actual file name\n",
    "\n",
    "# Preview\n",
    "print(df.head())\n",
    "\n",
    "# Optional: Drop missing transcripts if any\n",
    "df = df.dropna(subset=['transcript'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# 0 → dementia, 1 → non_dementia (depending on your dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d51951",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e94aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4be294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "for transcript in df['transcript']:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        transcript,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='np'  # if you're using TensorFlow, else use 'pt' for PyTorch\n",
    "    )\n",
    "    input_ids.append(encoded['input_ids'].squeeze(0))\n",
    "    attention_masks.append(encoded['attention_mask'].squeeze(0))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "input_ids = np.array(input_ids)\n",
    "attention_masks = np.array(attention_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aafbe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_text shape: (222, 128)\n",
      "X_mask shape: (222, 128)\n",
      "y shape: (222,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_text = np.array(input_ids)\n",
    "X_mask = np.array(attention_masks)\n",
    "y = np.array(df['label_encoded'])\n",
    "\n",
    "print(\"X_text shape:\", X_text.shape)\n",
    "print(\"X_mask shape:\", X_mask.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f94cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/216.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.9/216.1 MB 10.5 MB/s eta 0:00:21\n",
      "    --------------------------------------- 5.0/216.1 MB 10.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 5.5/216.1 MB 9.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 5.8/216.1 MB 7.7 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 6.3/216.1 MB 5.8 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 6.6/216.1 MB 5.2 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.8/216.1 MB 4.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 7.1/216.1 MB 4.4 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 7.3/216.1 MB 4.0 MB/s eta 0:00:52\n",
      "   - -------------------------------------- 7.6/216.1 MB 3.9 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 8.1/216.1 MB 3.5 MB/s eta 0:01:00\n",
      "   - -------------------------------------- 8.4/216.1 MB 3.3 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.7/216.1 MB 3.2 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 8.9/216.1 MB 3.1 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 9.4/216.1 MB 2.9 MB/s eta 0:01:11\n",
      "   - -------------------------------------- 9.7/216.1 MB 2.9 MB/s eta 0:01:12\n",
      "   - -------------------------------------- 10.0/216.1 MB 2.8 MB/s eta 0:01:13\n",
      "   - -------------------------------------- 10.5/216.1 MB 2.8 MB/s eta 0:01:15\n",
      "   - -------------------------------------- 10.7/216.1 MB 2.7 MB/s eta 0:01:16\n",
      "   -- ------------------------------------- 11.3/216.1 MB 2.7 MB/s eta 0:01:17\n",
      "   -- ------------------------------------- 11.5/216.1 MB 2.7 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 12.1/216.1 MB 2.6 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 12.6/216.1 MB 2.6 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 12.8/216.1 MB 2.6 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 13.4/216.1 MB 2.5 MB/s eta 0:01:20\n",
      "   -- ------------------------------------- 13.6/216.1 MB 2.5 MB/s eta 0:01:20\n",
      "   -- ------------------------------------- 14.2/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 14.7/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 15.2/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 15.5/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 16.0/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 16.5/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 17.0/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 17.3/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 17.8/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 18.4/216.1 MB 2.5 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 18.9/216.1 MB 2.5 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 19.4/216.1 MB 2.5 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 19.9/216.1 MB 2.5 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 20.4/216.1 MB 2.5 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 21.2/216.1 MB 2.5 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 21.8/216.1 MB 2.5 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.3/216.1 MB 2.5 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 22.8/216.1 MB 2.5 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 23.6/216.1 MB 2.5 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 24.1/216.1 MB 2.5 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 24.6/216.1 MB 2.5 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 25.4/216.1 MB 2.6 MB/s eta 0:01:15\n",
      "   ---- ----------------------------------- 26.0/216.1 MB 2.6 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 26.7/216.1 MB 2.6 MB/s eta 0:01:14\n",
      "   ----- ---------------------------------- 27.8/216.1 MB 2.6 MB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 28.6/216.1 MB 2.7 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 29.1/216.1 MB 2.7 MB/s eta 0:01:11\n",
      "   ----- ---------------------------------- 29.9/216.1 MB 2.7 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 30.7/216.1 MB 2.7 MB/s eta 0:01:09\n",
      "   ----- ---------------------------------- 31.7/216.1 MB 2.7 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 32.8/216.1 MB 2.8 MB/s eta 0:01:06\n",
      "   ------ --------------------------------- 33.8/216.1 MB 2.8 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 34.9/216.1 MB 2.9 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 36.2/216.1 MB 2.9 MB/s eta 0:01:02\n",
      "   ------ --------------------------------- 37.5/216.1 MB 3.0 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 39.1/216.1 MB 3.1 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 40.4/216.1 MB 3.1 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 41.2/216.1 MB 3.1 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 41.9/216.1 MB 3.1 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 42.7/216.1 MB 3.1 MB/s eta 0:00:56\n",
      "   -------- ------------------------------- 43.3/216.1 MB 3.1 MB/s eta 0:00:56\n",
      "   -------- ------------------------------- 44.0/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 44.6/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 45.1/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 45.9/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 46.4/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 46.9/216.1 MB 3.1 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 47.7/216.1 MB 3.1 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 48.5/216.1 MB 3.1 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 49.0/216.1 MB 3.1 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 49.8/216.1 MB 3.1 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 50.3/216.1 MB 3.1 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 51.1/216.1 MB 3.1 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 51.9/216.1 MB 3.2 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 52.7/216.1 MB 3.2 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 53.2/216.1 MB 3.1 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 53.7/216.1 MB 3.1 MB/s eta 0:00:52\n",
      "   ---------- ----------------------------- 54.5/216.1 MB 3.2 MB/s eta 0:00:52\n",
      "   ---------- ----------------------------- 55.1/216.1 MB 3.2 MB/s eta 0:00:52\n",
      "   ---------- ----------------------------- 55.8/216.1 MB 3.2 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 56.4/216.1 MB 3.2 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 57.1/216.1 MB 3.2 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 57.9/216.1 MB 3.2 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 58.7/216.1 MB 3.2 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 59.2/216.1 MB 3.2 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 60.0/216.1 MB 3.2 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 60.8/216.1 MB 3.2 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 61.6/216.1 MB 3.2 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 62.4/216.1 MB 3.2 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 63.2/216.1 MB 3.2 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 64.0/216.1 MB 3.2 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 64.7/216.1 MB 3.2 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 65.5/216.1 MB 3.2 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 66.3/216.1 MB 3.2 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 67.4/216.1 MB 3.2 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 68.2/216.1 MB 3.2 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 69.2/216.1 MB 3.3 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 70.0/216.1 MB 3.3 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 70.8/216.1 MB 3.3 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 71.6/216.1 MB 3.3 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 72.4/216.1 MB 3.3 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 73.4/216.1 MB 3.3 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 74.2/216.1 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 75.2/216.1 MB 3.3 MB/s eta 0:00:43\n",
      "   -------------- ------------------------- 76.0/216.1 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 76.8/216.1 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 77.9/216.1 MB 3.4 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 78.6/216.1 MB 3.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 79.7/216.1 MB 3.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 80.7/216.1 MB 3.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 81.5/216.1 MB 3.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 82.8/216.1 MB 3.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 83.9/216.1 MB 3.4 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 84.9/216.1 MB 3.4 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 86.2/216.1 MB 3.5 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 87.3/216.1 MB 3.5 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 88.6/216.1 MB 3.5 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 90.4/216.1 MB 3.5 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 91.2/216.1 MB 3.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 92.0/216.1 MB 3.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 92.5/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 93.1/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 93.6/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 94.1/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 94.6/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 95.2/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 95.9/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 96.5/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 97.0/216.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 97.8/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 98.3/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 99.1/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 99.6/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 100.4/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 100.9/216.1 MB 3.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 101.7/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 102.2/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 102.8/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 103.5/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 104.3/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 105.1/216.1 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 105.9/216.1 MB 3.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 106.4/216.1 MB 3.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 107.2/216.1 MB 3.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 108.0/216.1 MB 3.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 108.8/216.1 MB 3.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 109.6/216.1 MB 3.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 110.1/216.1 MB 3.4 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 110.9/216.1 MB 3.5 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 111.7/216.1 MB 3.5 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 112.5/216.1 MB 3.5 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 113.2/216.1 MB 3.5 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 113.8/216.1 MB 3.5 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 114.0/216.1 MB 3.5 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 114.6/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 115.1/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 115.3/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 115.9/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.1/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.4/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.4/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.4/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.4/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.4/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.7/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.7/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.7/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.7/216.1 MB 3.5 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 116.9/216.1 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.2/216.1 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.2/216.1 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.2/216.1 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.2/216.1 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.4/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.4/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 117.7/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 118.0/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 118.2/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 118.2/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 118.5/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 118.8/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 119.0/216.1 MB 3.3 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 119.3/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 119.5/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 119.8/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 120.1/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 120.6/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 120.8/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 121.1/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 121.4/216.1 MB 3.2 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 121.9/216.1 MB 3.1 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 122.2/216.1 MB 3.1 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 122.4/216.1 MB 3.1 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 122.9/216.1 MB 3.1 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 123.2/216.1 MB 3.1 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 123.7/216.1 MB 3.1 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 124.0/216.1 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 124.5/216.1 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 124.8/216.1 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 125.3/216.1 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 125.6/216.1 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 126.1/216.1 MB 2.9 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 126.4/216.1 MB 2.9 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 126.9/216.1 MB 2.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 127.4/216.1 MB 2.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 127.9/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 128.5/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 128.7/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 129.2/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 130.0/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 130.3/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 130.8/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 131.3/216.1 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 131.9/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 132.4/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 133.2/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 133.7/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 134.2/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 135.0/216.1 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 135.5/216.1 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 136.3/216.1 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 137.1/216.1 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 138.1/216.1 MB 2.8 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 138.9/216.1 MB 2.8 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 140.0/216.1 MB 2.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 141.0/216.1 MB 2.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 142.1/216.1 MB 2.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 142.6/216.1 MB 2.8 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 143.7/216.1 MB 2.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 144.7/216.1 MB 2.9 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 145.5/216.1 MB 2.9 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 146.3/216.1 MB 2.9 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 147.3/216.1 MB 2.9 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 148.4/216.1 MB 2.9 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 149.4/216.1 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 150.7/216.1 MB 2.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 151.8/216.1 MB 2.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 153.1/216.1 MB 2.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 154.1/216.1 MB 3.0 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 154.9/216.1 MB 3.0 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 155.7/216.1 MB 3.0 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 156.8/216.1 MB 3.0 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 157.5/216.1 MB 2.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 158.3/216.1 MB 2.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 159.1/216.1 MB 2.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 159.9/216.1 MB 2.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 160.7/216.1 MB 2.9 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 161.7/216.1 MB 2.9 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 162.8/216.1 MB 3.0 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 163.8/216.1 MB 3.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 164.9/216.1 MB 3.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 165.7/216.1 MB 3.0 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 166.5/216.1 MB 3.0 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 167.5/216.1 MB 3.0 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 168.3/216.1 MB 3.0 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 169.1/216.1 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 170.1/216.1 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 170.9/216.1 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 172.0/216.1 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 172.8/216.1 MB 2.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 173.8/216.1 MB 2.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 174.6/216.1 MB 2.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 175.6/216.1 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 176.7/216.1 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 177.5/216.1 MB 2.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 178.3/216.1 MB 2.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 179.3/216.1 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 180.6/216.1 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 181.7/216.1 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 182.5/216.1 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 183.5/216.1 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 184.3/216.1 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 185.3/216.1 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 186.4/216.1 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 187.4/216.1 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 188.2/216.1 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 189.3/216.1 MB 3.0 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 190.6/216.1 MB 3.1 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 191.9/216.1 MB 3.1 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 193.2/216.1 MB 3.1 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 194.0/216.1 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 195.0/216.1 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 195.8/216.1 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 196.9/216.1 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 197.9/216.1 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 199.0/216.1 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 200.0/216.1 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 201.1/216.1 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 202.4/216.1 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 203.4/216.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 204.5/216.1 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 205.5/216.1 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 206.3/216.1 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 207.1/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 207.9/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 208.1/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 208.7/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 209.2/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 209.5/216.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 210.0/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 210.5/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  211.0/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  211.3/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  211.8/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  212.3/216.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  212.9/216.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.4/216.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.9/216.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.4/216.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  215.0/216.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  215.5/216.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  216.0/216.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 216.1/216.1 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.14.0 torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7bd3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8249b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'dementia'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_with_transcripts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Optional: encode labels if not numeric\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Split\u001b[39;00m\n\u001b[0;32m      8\u001b[0m train_texts, val_texts, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m     10\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'dementia'"
     ]
    }
   ],
   "source": [
    "# Example: dataframe with two columns - 'transcript' and 'label'\n",
    "df = pd.read_csv(\"data_with_transcripts.csv\")  # Replace with your file\n",
    "\n",
    "# Optional: encode labels if not numeric\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['transcript'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45337841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dementia' 'nodementia']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672153e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map string labels to integers\n",
    "label_mapping = {\n",
    "    'dementia': 1,\n",
    "    'nodementia': 0\n",
    "}\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "\n",
    "# Step 2: Drop any rows where mapping failed (just in case)\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Step 3: Convert to integer (should work now)\n",
    "df['label'] = df['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "425eb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, datasets\n",
      "Successfully installed datasets-4.0.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f2f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb9bdd91ce4d07aa4b7cb0bccfc8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca84f67accc14bdb8335cde7fc4893d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load your cleaned data\n",
    "df = pd.read_csv(\"data_with_transcripts.csv\")\n",
    "\n",
    "# Label encoding\n",
    "df['label'] = df['label'].map({'nodementia': 0, 'dementia': 1})\n",
    "\n",
    "# Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['transcript'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Prepare Dataset objects\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f0cad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06100b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBertForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBertForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertForSequenceClassification, Trainer, TrainingArguments\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load BERT model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[0;32m      7\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      8\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./bert-dementia-output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1994\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1994\u001b[0m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1963\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1961\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1963\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nBertForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBertForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-dementia-output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "# Metric function\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
